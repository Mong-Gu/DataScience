{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div style align = 'center'>COMPAS 김해시 화재발생 예측모델 개발</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 반복 작업 시 이걸로.\n",
    "\n",
    "train = pd.read_csv('C:/develop/jupyter notebook/COMPAS/PJT002_train.csv', parse_dates=[\"dt_of_fr\"])\n",
    "val = pd.read_csv('C:/develop/jupyter notebook/COMPAS/PJT002_validation.csv', parse_dates=[\"dt_of_fr\"])\n",
    "test = pd.read_csv('C:/develop/jupyter notebook/COMPAS/PJT002_test.csv', parse_dates=[\"dt_of_fr\"])\n",
    "sub = pd.read_csv('C:/develop/jupyter notebook/COMPAS/PJT002_submission.csv')\n",
    "\n",
    "train[\"dt_year\"] = train[\"dt_of_fr\"].dt.year\n",
    "train[\"dt_month\"] = train[\"dt_of_fr\"].dt.month\n",
    "train[\"dt_day\"] = train[\"dt_of_fr\"].dt.day\n",
    "train[\"dt_hour\"] = train[\"dt_of_fr\"].dt.hour\n",
    "train[\"dt_minute\"] = train[\"dt_of_fr\"].dt.minute\n",
    "train[\"dt_dayofweek\"] = train[\"dt_of_fr\"].dt.dayofweek\n",
    "\n",
    "val[\"dt_year\"] = val[\"dt_of_fr\"].dt.year\n",
    "val[\"dt_month\"] = val[\"dt_of_fr\"].dt.month\n",
    "val[\"dt_day\"] = val[\"dt_of_fr\"].dt.day\n",
    "val[\"dt_hour\"] = val[\"dt_of_fr\"].dt.hour\n",
    "val[\"dt_minute\"] = val[\"dt_of_fr\"].dt.minute\n",
    "val[\"dt_dayofweek\"] = val[\"dt_of_fr\"].dt.dayofweek\n",
    "\n",
    "test[\"dt_year\"] = test[\"dt_of_fr\"].dt.year\n",
    "test[\"dt_month\"] = test[\"dt_of_fr\"].dt.month\n",
    "test[\"dt_day\"] = test[\"dt_of_fr\"].dt.day\n",
    "test[\"dt_hour\"] = test[\"dt_of_fr\"].dt.hour\n",
    "test[\"dt_minute\"] = test[\"dt_of_fr\"].dt.minute\n",
    "test[\"dt_dayofweek\"] = test[\"dt_of_fr\"].dt.dayofweek\n",
    "\n",
    "binary_y = {'N': 0, 'Y': 1}\n",
    "train['fr_yn'] = train['fr_yn'].map(binary_y)\n",
    "val['fr_yn'] = val['fr_yn'].map(binary_y)\n",
    "\n",
    "df_all = pd.concat([train, val, test])\n",
    "categorical_cols = df_all.select_dtypes(['object']).columns\n",
    "for col in categorical_cols:\n",
    "    df_all[col] = pd.Categorical(df_all[col]).codes\n",
    "    \n",
    "train = df_all[:len(train)]\n",
    "val = df_all[len(train):-len(test)]\n",
    "test = df_all[-len(test):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(['fr_yn', 'dt_of_fr', 'id'], 1)\n",
    "y_train = train['fr_yn']\n",
    "X_val = val.drop(['fr_yn', 'dt_of_fr', 'id'], 1)\n",
    "y_val = val['fr_yn']\n",
    "test = test.drop(['fr_yn', 'dt_of_fr', 'id'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.fillna(X_train.mean()) \n",
    "X_val = X_val.fillna(X_val.mean()) \n",
    "test = test.fillna(test.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Import Module</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: missingno in c:\\users\\user\\anaconda3\\lib\\site-packages (0.4.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\lib\\site-packages (from missingno) (1.16.4)\n",
      "Requirement already satisfied: seaborn in c:\\users\\user\\anaconda3\\lib\\site-packages (from missingno) (0.9.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\user\\anaconda3\\lib\\site-packages (from missingno) (3.1.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\user\\anaconda3\\lib\\site-packages (from missingno) (1.2.1)\n",
      "Requirement already satisfied: pandas>=0.15.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from seaborn->missingno) (0.24.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->missingno) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->missingno) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->missingno) (2.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib->missingno) (2.8.0)\n",
      "Requirement already satisfied: pytz>=2011k in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas>=0.15.2->seaborn->missingno) (2019.1)\n",
      "Requirement already satisfied: six in c:\\users\\user\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib->missingno) (1.12.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\anaconda3\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib->missingno) (41.0.1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "!pip install missingno\n",
    "import missingno as msno\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Load Dataset</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dt_of_fr은 날짜로 해석하기 위해 parse_dates 옵션 추가\n",
    "train = pd.read_csv('C:/develop/jupyter notebook/COMPAS/PJT002_train.csv', parse_dates=[\"dt_of_fr\"])\n",
    "val = pd.read_csv('C:/develop/jupyter notebook/COMPAS/PJT002_validation.csv', parse_dates=[\"dt_of_fr\"])\n",
    "test = pd.read_csv('C:/develop/jupyter notebook/COMPAS/PJT002_test.csv', parse_dates=[\"dt_of_fr\"])\n",
    "sub = pd.read_csv('C:/develop/jupyter notebook/COMPAS/PJT002_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Data Check</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.shape)\n",
    "print(val.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train dataset에 대한 간단한 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NULL Data Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column:   dt_of_fr\t Percent of NaN value: 0.00%\n",
      "column:      fr_yn\t Percent of NaN value: 0.00%\n",
      "column:   bldng_us\t Percent of NaN value: 46.75%\n",
      "column: bldng_archtctr\t Percent of NaN value: 46.73%\n",
      "column:  bldng_cnt\t Percent of NaN value: 0.00%\n",
      "column:   bldng_ar\t Percent of NaN value: 0.00%\n",
      "column:     ttl_ar\t Percent of NaN value: 0.00%\n",
      "column:     lnd_ar\t Percent of NaN value: 0.00%\n",
      "column: dt_of_athrztn\t Percent of NaN value: 46.59%\n",
      "column: ttl_grnd_flr\t Percent of NaN value: 17.25%\n",
      "column: ttl_dwn_flr\t Percent of NaN value: 18.59%\n",
      "column: bldng_us_clssfctn\t Percent of NaN value: 49.57%\n",
      "column:     tmprtr\t Percent of NaN value: 0.02%\n",
      "column:    prcpttn\t Percent of NaN value: 90.59%\n",
      "column:    wnd_spd\t Percent of NaN value: 0.06%\n",
      "column:  wnd_drctn\t Percent of NaN value: 0.37%\n",
      "column:       hmdt\t Percent of NaN value: 0.04%\n",
      "column: gas_engry_us_201401\t Percent of NaN value: 46.59%\n",
      "column: ele_engry_us_201401\t Percent of NaN value: 46.59%\n",
      "column: gas_engry_us_201402\t Percent of NaN value: 46.59%\n",
      "column: ele_engry_us_201402\t Percent of NaN value: 46.59%\n",
      "column: gas_engry_us_201403\t Percent of NaN value: 46.59%\n",
      "column: ele_engry_us_201403\t Percent of NaN value: 46.59%\n",
      "column: gas_engry_us_201404\t Percent of NaN value: 46.59%\n",
      "column: ele_engry_us_201404\t Percent of NaN value: 46.59%\n",
      "column: gas_engry_us_201405\t Percent of NaN value: 46.59%\n",
      "column: ele_engry_us_201405\t Percent of NaN value: 46.59%\n",
      "column: gas_engry_us_201406\t Percent of NaN value: 46.59%\n",
      "column: ele_engry_us_201406\t Percent of NaN value: 46.59%\n",
      "column: gas_engry_us_201407\t Percent of NaN value: 46.59%\n",
      "column: ele_engry_us_201407\t Percent of NaN value: 46.59%\n",
      "column: gas_engry_us_201408\t Percent of NaN value: 46.59%\n",
      "column: ele_engry_us_201408\t Percent of NaN value: 46.59%\n",
      "column: gas_engry_us_201409\t Percent of NaN value: 46.59%\n",
      "column: ele_engry_us_201409\t Percent of NaN value: 46.59%\n",
      "column: gas_engry_us_201410\t Percent of NaN value: 46.59%\n",
      "column: ele_engry_us_201410\t Percent of NaN value: 46.59%\n",
      "column: gas_engry_us_201411\t Percent of NaN value: 46.59%\n",
      "column: ele_engry_us_201411\t Percent of NaN value: 46.59%\n",
      "column: gas_engry_us_201412\t Percent of NaN value: 46.59%\n",
      "column: ele_engry_us_201412\t Percent of NaN value: 46.59%\n",
      "column: gas_engry_us_201501\t Percent of NaN value: 46.59%\n",
      "column: ele_engry_us_201501\t Percent of NaN value: 46.59%\n",
      "column: gas_engry_us_201502\t Percent of NaN value: 46.59%\n",
      "column: ele_engry_us_201502\t Percent of NaN value: 46.59%\n",
      "column: gas_engry_us_201503\t Percent of NaN value: 46.59%\n",
      "column: ele_engry_us_201503\t Percent of NaN value: 46.59%\n",
      "column: gas_engry_us_201504\t Percent of NaN value: 46.59%\n",
      "column: ele_engry_us_201504\t Percent of NaN value: 46.59%\n",
      "column: gas_engry_us_201505\t Percent of NaN value: 46.59%\n",
      "column: ele_engry_us_201505\t Percent of NaN value: 46.59%\n",
      "column: gas_engry_us_201506\t Percent of NaN value: 46.59%\n",
      "column: ele_engry_us_201506\t Percent of NaN value: 46.59%\n",
      "column: gas_engry_us_201507\t Percent of NaN value: 46.59%\n",
      "column: ele_engry_us_201507\t Percent of NaN value: 46.59%\n",
      "column: gas_engry_us_201508\t Percent of NaN value: 46.59%\n",
      "column: ele_engry_us_201508\t Percent of NaN value: 46.59%\n",
      "column: gas_engry_us_201509\t Percent of NaN value: 46.59%\n",
      "column: ele_engry_us_201509\t Percent of NaN value: 46.59%\n",
      "column: gas_engry_us_201510\t Percent of NaN value: 46.59%\n",
      "column: ele_engry_us_201510\t Percent of NaN value: 46.59%\n",
      "column: gas_engry_us_201511\t Percent of NaN value: 46.59%\n",
      "column: ele_engry_us_201511\t Percent of NaN value: 46.59%\n",
      "column: gas_engry_us_201512\t Percent of NaN value: 46.59%\n",
      "column: ele_engry_us_201512\t Percent of NaN value: 46.59%\n",
      "column: gas_engry_us_201601\t Percent of NaN value: 46.59%\n",
      "column: ele_engry_us_201601\t Percent of NaN value: 46.59%\n",
      "column: gas_engry_us_201602\t Percent of NaN value: 46.59%\n",
      "column: ele_engry_us_201602\t Percent of NaN value: 46.59%\n",
      "column: gas_engry_us_201603\t Percent of NaN value: 46.59%\n",
      "column: ele_engry_us_201603\t Percent of NaN value: 46.59%\n",
      "column: gas_engry_us_201604\t Percent of NaN value: 46.59%\n",
      "column: ele_engry_us_201604\t Percent of NaN value: 46.59%\n",
      "column: gas_engry_us_201605\t Percent of NaN value: 46.59%\n",
      "column: ele_engry_us_201605\t Percent of NaN value: 46.59%\n",
      "column: gas_engry_us_201606\t Percent of NaN value: 46.59%\n",
      "column: ele_engry_us_201606\t Percent of NaN value: 46.59%\n",
      "column: gas_engry_us_201607\t Percent of NaN value: 46.59%\n",
      "column: ele_engry_us_201607\t Percent of NaN value: 46.59%\n",
      "column: gas_engry_us_201608\t Percent of NaN value: 46.59%\n",
      "column: ele_engry_us_201608\t Percent of NaN value: 46.59%\n",
      "column: gas_engry_us_201609\t Percent of NaN value: 46.59%\n",
      "column: ele_engry_us_201609\t Percent of NaN value: 46.59%\n",
      "column: gas_engry_us_201610\t Percent of NaN value: 46.59%\n",
      "column: ele_engry_us_201610\t Percent of NaN value: 46.59%\n",
      "column: gas_engry_us_201611\t Percent of NaN value: 46.59%\n",
      "column: ele_engry_us_201611\t Percent of NaN value: 46.59%\n",
      "column: gas_engry_us_201612\t Percent of NaN value: 46.59%\n",
      "column: ele_engry_us_201612\t Percent of NaN value: 46.59%\n",
      "column: gas_engry_us_201701\t Percent of NaN value: 46.59%\n",
      "column: ele_engry_us_201701\t Percent of NaN value: 46.59%\n",
      "column: gas_engry_us_201702\t Percent of NaN value: 46.59%\n",
      "column: ele_engry_us_201702\t Percent of NaN value: 46.59%\n",
      "column: gas_engry_us_201703\t Percent of NaN value: 46.59%\n",
      "column: ele_engry_us_201703\t Percent of NaN value: 46.59%\n",
      "column: gas_engry_us_201704\t Percent of NaN value: 46.59%\n",
      "column: ele_engry_us_201704\t Percent of NaN value: 46.59%\n",
      "column: gas_engry_us_201705\t Percent of NaN value: 46.59%\n",
      "column: ele_engry_us_201705\t Percent of NaN value: 46.59%\n",
      "column: gas_engry_us_201706\t Percent of NaN value: 46.59%\n",
      "column: ele_engry_us_201706\t Percent of NaN value: 46.59%\n",
      "column: gas_engry_us_201707\t Percent of NaN value: 46.59%\n",
      "column: ele_engry_us_201707\t Percent of NaN value: 46.59%\n",
      "column: gas_engry_us_201708\t Percent of NaN value: 46.59%\n",
      "column: ele_engry_us_201708\t Percent of NaN value: 46.59%\n",
      "column: gas_engry_us_201709\t Percent of NaN value: 46.59%\n",
      "column: ele_engry_us_201709\t Percent of NaN value: 46.59%\n",
      "column: gas_engry_us_201710\t Percent of NaN value: 46.59%\n",
      "column: ele_engry_us_201710\t Percent of NaN value: 46.59%\n",
      "column: gas_engry_us_201711\t Percent of NaN value: 46.59%\n",
      "column: ele_engry_us_201711\t Percent of NaN value: 46.59%\n",
      "column: gas_engry_us_201712\t Percent of NaN value: 46.59%\n",
      "column: ele_engry_us_201712\t Percent of NaN value: 46.59%\n",
      "column: gas_engry_us_201801\t Percent of NaN value: 46.59%\n",
      "column: ele_engry_us_201801\t Percent of NaN value: 46.59%\n",
      "column: gas_engry_us_201802\t Percent of NaN value: 46.59%\n",
      "column: ele_engry_us_201802\t Percent of NaN value: 46.59%\n",
      "column: gas_engry_us_201803\t Percent of NaN value: 46.59%\n",
      "column: ele_engry_us_201803\t Percent of NaN value: 46.59%\n",
      "column: gas_engry_us_201804\t Percent of NaN value: 46.59%\n",
      "column: ele_engry_us_201804\t Percent of NaN value: 46.59%\n",
      "column: gas_engry_us_201805\t Percent of NaN value: 46.59%\n",
      "column: ele_engry_us_201805\t Percent of NaN value: 46.59%\n",
      "column: gas_engry_us_201806\t Percent of NaN value: 46.59%\n",
      "column: ele_engry_us_201806\t Percent of NaN value: 46.59%\n",
      "column: gas_engry_us_201807\t Percent of NaN value: 46.59%\n",
      "column: ele_engry_us_201807\t Percent of NaN value: 46.59%\n",
      "column: gas_engry_us_201808\t Percent of NaN value: 46.59%\n",
      "column: ele_engry_us_201808\t Percent of NaN value: 46.59%\n",
      "column: gas_engry_us_201809\t Percent of NaN value: 46.59%\n",
      "column: ele_engry_us_201809\t Percent of NaN value: 46.59%\n",
      "column: gas_engry_us_201810\t Percent of NaN value: 46.59%\n",
      "column: ele_engry_us_201810\t Percent of NaN value: 46.59%\n",
      "column: gas_engry_us_201811\t Percent of NaN value: 46.59%\n",
      "column: ele_engry_us_201811\t Percent of NaN value: 46.59%\n",
      "column: gas_engry_us_201812\t Percent of NaN value: 46.59%\n",
      "column: ele_engry_us_201812\t Percent of NaN value: 46.59%\n",
      "column: lw_13101010\t Percent of NaN value: 99.49%\n",
      "column: lw_13101110\t Percent of NaN value: 99.51%\n",
      "column: lw_13101210\t Percent of NaN value: 99.50%\n",
      "column: lw_13101211\t Percent of NaN value: 99.50%\n",
      "column: lw_13101310\t Percent of NaN value: 99.51%\n",
      "column: lw_13101410\t Percent of NaN value: 99.52%\n",
      "column: lw_13111010\t Percent of NaN value: 99.49%\n",
      "column: lw_13111110\t Percent of NaN value: 99.53%\n",
      "column: lw_13121010\t Percent of NaN value: 99.54%\n",
      "column: lw_13121011\t Percent of NaN value: 99.54%\n",
      "column: lw_13131010\t Percent of NaN value: 99.50%\n",
      "column: lw_13131110\t Percent of NaN value: 99.50%\n",
      "column: lw_13141010\t Percent of NaN value: 99.51%\n",
      "column: lw_13141011\t Percent of NaN value: 99.51%\n",
      "column:        jmk\t Percent of NaN value: 0.00%\n",
      "column:         id\t Percent of NaN value: 0.00%\n",
      "column: rgnl_ar_nm\t Percent of NaN value: 2.52%\n",
      "column: rgnl_ar_nm2\t Percent of NaN value: 2.52%\n",
      "column: lnd_us_sttn_nm\t Percent of NaN value: 3.00%\n",
      "column:   rd_sd_nm\t Percent of NaN value: 2.52%\n",
      "column:     emd_nm\t Percent of NaN value: 0.01%\n",
      "column:     hm_cnt\t Percent of NaN value: 1.18%\n",
      "column: fr_sttn_dstnc\t Percent of NaN value: 0.00%\n",
      "column: bldng_ar_prc\t Percent of NaN value: 36.99%\n",
      "column: fr_wthr_fclt_dstnc\t Percent of NaN value: 0.00%\n",
      "column:  fr_mn_cnt\t Percent of NaN value: 0.07%\n",
      "column:  mlt_us_yn\t Percent of NaN value: 0.00%\n",
      "column: cctv_dstnc\t Percent of NaN value: 0.00%\n",
      "column: fr_wthr_fclt_in_100m\t Percent of NaN value: 0.00%\n",
      "column: cctv_in_100m\t Percent of NaN value: 0.00%\n",
      "column: tbc_rtl_str_dstnc\t Percent of NaN value: 0.00%\n",
      "column: sft_emrgnc_bll_dstnc\t Percent of NaN value: 0.00%\n",
      "column: ahsm_dstnc\t Percent of NaN value: 0.00%\n",
      "column: no_tbc_zn_dstnc\t Percent of NaN value: 0.00%\n",
      "column: bldng_cnt_in_50m\t Percent of NaN value: 0.00%\n",
      "column:  trgt_crtr\t Percent of NaN value: 86.19%\n",
      "column: fr_fghtng_fclt_spcl_css_5_yn\t Percent of NaN value: 85.75%\n",
      "column: fr_fghtng_fclt_spcl_css_6_yn\t Percent of NaN value: 85.75%\n",
      "column:      us_yn\t Percent of NaN value: 83.53%\n",
      "column: dngrs_thng_yn\t Percent of NaN value: 83.53%\n",
      "column: slf_fr_brgd_yn\t Percent of NaN value: 83.53%\n",
      "column: blk_dngrs_thng_mnfctr_yn\t Percent of NaN value: 83.53%\n",
      "column: cltrl_hrtg_yn\t Percent of NaN value: 83.53%\n"
     ]
    }
   ],
   "source": [
    "# train data의 NULL Data Check\n",
    "for col in train.columns:\n",
    "    msg = 'column: {:>10}\\t Percent of NaN value: {:.2f}%'.format(col, 100 * (train[col].isnull().sum() / train[col].shape[0]))\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column:   dt_of_fr\t Percent of NaN value: 0.00%\n",
      "column:   bldng_us\t Percent of NaN value: 15.86%\n",
      "column: bldng_archtctr\t Percent of NaN value: 15.56%\n",
      "column:  bldng_cnt\t Percent of NaN value: 0.00%\n",
      "column:   bldng_ar\t Percent of NaN value: 0.00%\n",
      "column:     ttl_ar\t Percent of NaN value: 0.00%\n",
      "column:     lnd_ar\t Percent of NaN value: 0.00%\n",
      "column: dt_of_athrztn\t Percent of NaN value: 15.56%\n",
      "column: ttl_grnd_flr\t Percent of NaN value: 11.60%\n",
      "column: ttl_dwn_flr\t Percent of NaN value: 13.49%\n",
      "column: bldng_us_clssfctn\t Percent of NaN value: 23.23%\n",
      "column:     tmprtr\t Percent of NaN value: 0.03%\n",
      "column:    prcpttn\t Percent of NaN value: 92.66%\n",
      "column:    wnd_spd\t Percent of NaN value: 0.03%\n",
      "column:  wnd_drctn\t Percent of NaN value: 0.14%\n",
      "column:       hmdt\t Percent of NaN value: 0.07%\n",
      "column: gas_engry_us_201401\t Percent of NaN value: 15.56%\n",
      "column: ele_engry_us_201401\t Percent of NaN value: 15.56%\n",
      "column: gas_engry_us_201402\t Percent of NaN value: 15.56%\n",
      "column: ele_engry_us_201402\t Percent of NaN value: 15.56%\n",
      "column: gas_engry_us_201403\t Percent of NaN value: 15.56%\n",
      "column: ele_engry_us_201403\t Percent of NaN value: 15.56%\n",
      "column: gas_engry_us_201404\t Percent of NaN value: 15.56%\n",
      "column: ele_engry_us_201404\t Percent of NaN value: 15.56%\n",
      "column: gas_engry_us_201405\t Percent of NaN value: 15.56%\n",
      "column: ele_engry_us_201405\t Percent of NaN value: 15.56%\n",
      "column: gas_engry_us_201406\t Percent of NaN value: 15.56%\n",
      "column: ele_engry_us_201406\t Percent of NaN value: 15.56%\n",
      "column: gas_engry_us_201407\t Percent of NaN value: 15.56%\n",
      "column: ele_engry_us_201407\t Percent of NaN value: 15.56%\n",
      "column: gas_engry_us_201408\t Percent of NaN value: 15.56%\n",
      "column: ele_engry_us_201408\t Percent of NaN value: 15.56%\n",
      "column: gas_engry_us_201409\t Percent of NaN value: 15.56%\n",
      "column: ele_engry_us_201409\t Percent of NaN value: 15.56%\n",
      "column: gas_engry_us_201410\t Percent of NaN value: 15.56%\n",
      "column: ele_engry_us_201410\t Percent of NaN value: 15.56%\n",
      "column: gas_engry_us_201411\t Percent of NaN value: 15.56%\n",
      "column: ele_engry_us_201411\t Percent of NaN value: 15.56%\n",
      "column: gas_engry_us_201412\t Percent of NaN value: 15.56%\n",
      "column: ele_engry_us_201412\t Percent of NaN value: 15.56%\n",
      "column: gas_engry_us_201501\t Percent of NaN value: 15.56%\n",
      "column: ele_engry_us_201501\t Percent of NaN value: 15.56%\n",
      "column: gas_engry_us_201502\t Percent of NaN value: 15.56%\n",
      "column: ele_engry_us_201502\t Percent of NaN value: 15.56%\n",
      "column: gas_engry_us_201503\t Percent of NaN value: 15.56%\n",
      "column: ele_engry_us_201503\t Percent of NaN value: 15.56%\n",
      "column: gas_engry_us_201504\t Percent of NaN value: 15.56%\n",
      "column: ele_engry_us_201504\t Percent of NaN value: 15.56%\n",
      "column: gas_engry_us_201505\t Percent of NaN value: 15.56%\n",
      "column: ele_engry_us_201505\t Percent of NaN value: 15.56%\n",
      "column: gas_engry_us_201506\t Percent of NaN value: 15.56%\n",
      "column: ele_engry_us_201506\t Percent of NaN value: 15.56%\n",
      "column: gas_engry_us_201507\t Percent of NaN value: 15.56%\n",
      "column: ele_engry_us_201507\t Percent of NaN value: 15.56%\n",
      "column: gas_engry_us_201508\t Percent of NaN value: 15.56%\n",
      "column: ele_engry_us_201508\t Percent of NaN value: 15.56%\n",
      "column: gas_engry_us_201509\t Percent of NaN value: 15.56%\n",
      "column: ele_engry_us_201509\t Percent of NaN value: 15.56%\n",
      "column: gas_engry_us_201510\t Percent of NaN value: 15.56%\n",
      "column: ele_engry_us_201510\t Percent of NaN value: 15.56%\n",
      "column: gas_engry_us_201511\t Percent of NaN value: 15.56%\n",
      "column: ele_engry_us_201511\t Percent of NaN value: 15.56%\n",
      "column: gas_engry_us_201512\t Percent of NaN value: 15.56%\n",
      "column: ele_engry_us_201512\t Percent of NaN value: 15.56%\n",
      "column: gas_engry_us_201601\t Percent of NaN value: 15.56%\n",
      "column: ele_engry_us_201601\t Percent of NaN value: 15.56%\n",
      "column: gas_engry_us_201602\t Percent of NaN value: 15.56%\n",
      "column: ele_engry_us_201602\t Percent of NaN value: 15.56%\n",
      "column: gas_engry_us_201603\t Percent of NaN value: 15.56%\n",
      "column: ele_engry_us_201603\t Percent of NaN value: 15.56%\n",
      "column: gas_engry_us_201604\t Percent of NaN value: 15.56%\n",
      "column: ele_engry_us_201604\t Percent of NaN value: 15.56%\n",
      "column: gas_engry_us_201605\t Percent of NaN value: 15.56%\n",
      "column: ele_engry_us_201605\t Percent of NaN value: 15.56%\n",
      "column: gas_engry_us_201606\t Percent of NaN value: 15.56%\n",
      "column: ele_engry_us_201606\t Percent of NaN value: 15.56%\n",
      "column: gas_engry_us_201607\t Percent of NaN value: 15.56%\n",
      "column: ele_engry_us_201607\t Percent of NaN value: 15.56%\n",
      "column: gas_engry_us_201608\t Percent of NaN value: 15.56%\n",
      "column: ele_engry_us_201608\t Percent of NaN value: 15.56%\n",
      "column: gas_engry_us_201609\t Percent of NaN value: 15.56%\n",
      "column: ele_engry_us_201609\t Percent of NaN value: 15.56%\n",
      "column: gas_engry_us_201610\t Percent of NaN value: 15.56%\n",
      "column: ele_engry_us_201610\t Percent of NaN value: 15.56%\n",
      "column: gas_engry_us_201611\t Percent of NaN value: 15.56%\n",
      "column: ele_engry_us_201611\t Percent of NaN value: 15.56%\n",
      "column: gas_engry_us_201612\t Percent of NaN value: 15.56%\n",
      "column: ele_engry_us_201612\t Percent of NaN value: 15.56%\n",
      "column: gas_engry_us_201701\t Percent of NaN value: 15.56%\n",
      "column: ele_engry_us_201701\t Percent of NaN value: 15.56%\n",
      "column: gas_engry_us_201702\t Percent of NaN value: 15.56%\n",
      "column: ele_engry_us_201702\t Percent of NaN value: 15.56%\n",
      "column: gas_engry_us_201703\t Percent of NaN value: 15.56%\n",
      "column: ele_engry_us_201703\t Percent of NaN value: 15.56%\n",
      "column: gas_engry_us_201704\t Percent of NaN value: 15.56%\n",
      "column: ele_engry_us_201704\t Percent of NaN value: 15.56%\n",
      "column: gas_engry_us_201705\t Percent of NaN value: 15.56%\n",
      "column: ele_engry_us_201705\t Percent of NaN value: 15.56%\n",
      "column: gas_engry_us_201706\t Percent of NaN value: 15.56%\n",
      "column: ele_engry_us_201706\t Percent of NaN value: 15.56%\n",
      "column: gas_engry_us_201707\t Percent of NaN value: 15.56%\n",
      "column: ele_engry_us_201707\t Percent of NaN value: 15.56%\n",
      "column: gas_engry_us_201708\t Percent of NaN value: 15.56%\n",
      "column: ele_engry_us_201708\t Percent of NaN value: 15.56%\n",
      "column: gas_engry_us_201709\t Percent of NaN value: 15.56%\n",
      "column: ele_engry_us_201709\t Percent of NaN value: 15.56%\n",
      "column: gas_engry_us_201710\t Percent of NaN value: 15.56%\n",
      "column: ele_engry_us_201710\t Percent of NaN value: 15.56%\n",
      "column: gas_engry_us_201711\t Percent of NaN value: 15.56%\n",
      "column: ele_engry_us_201711\t Percent of NaN value: 15.56%\n",
      "column: gas_engry_us_201712\t Percent of NaN value: 15.56%\n",
      "column: ele_engry_us_201712\t Percent of NaN value: 15.56%\n",
      "column: gas_engry_us_201801\t Percent of NaN value: 15.56%\n",
      "column: ele_engry_us_201801\t Percent of NaN value: 15.56%\n",
      "column: gas_engry_us_201802\t Percent of NaN value: 15.56%\n",
      "column: ele_engry_us_201802\t Percent of NaN value: 15.56%\n",
      "column: gas_engry_us_201803\t Percent of NaN value: 15.56%\n",
      "column: ele_engry_us_201803\t Percent of NaN value: 15.56%\n",
      "column: gas_engry_us_201804\t Percent of NaN value: 15.56%\n",
      "column: ele_engry_us_201804\t Percent of NaN value: 15.56%\n",
      "column: gas_engry_us_201805\t Percent of NaN value: 15.56%\n",
      "column: ele_engry_us_201805\t Percent of NaN value: 15.56%\n",
      "column: gas_engry_us_201806\t Percent of NaN value: 15.56%\n",
      "column: ele_engry_us_201806\t Percent of NaN value: 15.56%\n",
      "column: gas_engry_us_201807\t Percent of NaN value: 15.56%\n",
      "column: ele_engry_us_201807\t Percent of NaN value: 15.56%\n",
      "column: gas_engry_us_201808\t Percent of NaN value: 15.56%\n",
      "column: ele_engry_us_201808\t Percent of NaN value: 15.56%\n",
      "column: gas_engry_us_201809\t Percent of NaN value: 15.56%\n",
      "column: ele_engry_us_201809\t Percent of NaN value: 15.56%\n",
      "column: gas_engry_us_201810\t Percent of NaN value: 15.56%\n",
      "column: ele_engry_us_201810\t Percent of NaN value: 15.56%\n",
      "column: gas_engry_us_201811\t Percent of NaN value: 15.56%\n",
      "column: ele_engry_us_201811\t Percent of NaN value: 15.56%\n",
      "column: gas_engry_us_201812\t Percent of NaN value: 15.56%\n",
      "column: ele_engry_us_201812\t Percent of NaN value: 15.56%\n",
      "column: lw_13101010\t Percent of NaN value: 98.65%\n",
      "column: lw_13101110\t Percent of NaN value: 98.65%\n",
      "column: lw_13101210\t Percent of NaN value: 98.65%\n",
      "column: lw_13101211\t Percent of NaN value: 98.65%\n",
      "column: lw_13101310\t Percent of NaN value: 98.65%\n",
      "column: lw_13101410\t Percent of NaN value: 98.65%\n",
      "column: lw_13111010\t Percent of NaN value: 98.65%\n",
      "column: lw_13111110\t Percent of NaN value: 98.65%\n",
      "column: lw_13121010\t Percent of NaN value: 98.65%\n",
      "column: lw_13121011\t Percent of NaN value: 98.65%\n",
      "column: lw_13131010\t Percent of NaN value: 98.65%\n",
      "column: lw_13131110\t Percent of NaN value: 98.65%\n",
      "column: lw_13141010\t Percent of NaN value: 98.65%\n",
      "column: lw_13141011\t Percent of NaN value: 98.65%\n",
      "column:        jmk\t Percent of NaN value: 0.00%\n",
      "column:         id\t Percent of NaN value: 0.00%\n",
      "column: rgnl_ar_nm\t Percent of NaN value: 1.39%\n",
      "column: rgnl_ar_nm2\t Percent of NaN value: 1.39%\n",
      "column: lnd_us_sttn_nm\t Percent of NaN value: 2.47%\n",
      "column:   rd_sd_nm\t Percent of NaN value: 1.39%\n",
      "column:     emd_nm\t Percent of NaN value: 0.00%\n",
      "column:     hm_cnt\t Percent of NaN value: 0.00%\n",
      "column: fr_sttn_dstnc\t Percent of NaN value: 0.00%\n",
      "column: bldng_ar_prc\t Percent of NaN value: 45.45%\n",
      "column: fr_wthr_fclt_dstnc\t Percent of NaN value: 0.00%\n",
      "column:  fr_mn_cnt\t Percent of NaN value: 0.00%\n",
      "column:  mlt_us_yn\t Percent of NaN value: 0.00%\n",
      "column: cctv_dstnc\t Percent of NaN value: 0.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column: fr_wthr_fclt_in_100m\t Percent of NaN value: 0.00%\n",
      "column: cctv_in_100m\t Percent of NaN value: 0.00%\n",
      "column: tbc_rtl_str_dstnc\t Percent of NaN value: 0.00%\n",
      "column: sft_emrgnc_bll_dstnc\t Percent of NaN value: 0.00%\n",
      "column: ahsm_dstnc\t Percent of NaN value: 0.00%\n",
      "column: no_tbc_zn_dstnc\t Percent of NaN value: 0.00%\n",
      "column: bldng_cnt_in_50m\t Percent of NaN value: 0.00%\n",
      "column:  trgt_crtr\t Percent of NaN value: 92.12%\n",
      "column: fr_fghtng_fclt_spcl_css_5_yn\t Percent of NaN value: 81.16%\n",
      "column: fr_fghtng_fclt_spcl_css_6_yn\t Percent of NaN value: 81.16%\n",
      "column:      us_yn\t Percent of NaN value: 78.39%\n",
      "column: dngrs_thng_yn\t Percent of NaN value: 78.39%\n",
      "column: slf_fr_brgd_yn\t Percent of NaN value: 78.39%\n",
      "column: blk_dngrs_thng_mnfctr_yn\t Percent of NaN value: 78.39%\n",
      "column: cltrl_hrtg_yn\t Percent of NaN value: 78.39%\n",
      "column:      fr_yn\t Percent of NaN value: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# test data의 NULL Data Check\n",
    "for col in test.columns:\n",
    "    msg = 'column: {:>10}\\t Percent of NaN value: {:.2f}%'.format(col, 100 * (test[col].isnull().sum() / test[col].shape[0]))\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결측치의 비율이 심각한 column들이 많으나 일단 첫 번째 모델에는 모든 변수를 투입하겠다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Target Lable Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train Dataset 에서 화재 발생 비율\n",
    "f, ax = plt.subplots(1, 2, figsize=(18, 8))\n",
    "train['fr_yn'].value_counts().plot.pie(explode=[0, 0.1], autopct='%1.1f%%', ax=ax[0], shadow=True)\n",
    "ax[0].set_title('Pie plot - fr_yn')\n",
    "ax[0].set_ylabel('')\n",
    "sns.countplot('fr_yn', data=train, ax=ax[1])\n",
    "ax[1].set_title('Count plot - fr_yn')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation Dataset 에서 화재 발생 비율\n",
    "f, ax = plt.subplots(1, 2, figsize=(18, 8))\n",
    "\n",
    "val['fr_yn'].value_counts().plot.pie(explode=[0, 0.1], autopct='%1.1f%%', ax=ax[0], shadow=True)\n",
    "ax[0].set_title('Pie plot - fr_yn')\n",
    "ax[0].set_ylabel('')\n",
    "sns.countplot('fr_yn', data=val, ax=ax[1])\n",
    "ax[1].set_title('Count plot - fr_yn')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target Lable을 살펴본 결과, 하나의 결과값에 치우져있지 않기 때문에 분석하기에 무리가 없는 데이터라고 판단한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>EDA</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train.dt_of_fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"dt_year\"] = train[\"dt_of_fr\"].dt.year\n",
    "train[\"dt_month\"] = train[\"dt_of_fr\"].dt.month\n",
    "train[\"dt_day\"] = train[\"dt_of_fr\"].dt.day\n",
    "train[\"dt_hour\"] = train[\"dt_of_fr\"].dt.hour\n",
    "train[\"dt_minute\"] = train[\"dt_of_fr\"].dt.minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dayofweek는 날짜에서 요일(월~일)을 가져오는 기능.\n",
    "# 값은 0(월), 1(화), 2(수), 3(목), 4(금), 5(토), 6(일) 을 나타냄.\n",
    "train[\"dt_dayofweek\"] = train[\"dt_of_fr\"].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[[\"dt_of_fr\", \"dt_year\", \"dt_month\", \"dt_day\", \"dt_hour\", \"dt_minute\", \"dt_dayofweek\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "validation dataset과 test dataset에도 동일한 작업을 진행하겠다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "val[\"dt_year\"] = val[\"dt_of_fr\"].dt.year\n",
    "val[\"dt_month\"] = val[\"dt_of_fr\"].dt.month\n",
    "val[\"dt_day\"] = val[\"dt_of_fr\"].dt.day\n",
    "val[\"dt_hour\"] = val[\"dt_of_fr\"].dt.hour\n",
    "val[\"dt_minute\"] = val[\"dt_of_fr\"].dt.minute\n",
    "val[\"dt_dayofweek\"] = val[\"dt_of_fr\"].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"dt_year\"] = test[\"dt_of_fr\"].dt.year\n",
    "test[\"dt_month\"] = test[\"dt_of_fr\"].dt.month\n",
    "test[\"dt_day\"] = test[\"dt_of_fr\"].dt.day\n",
    "test[\"dt_hour\"] = test[\"dt_of_fr\"].dt.hour\n",
    "test[\"dt_minute\"] = test[\"dt_of_fr\"].dt.minute\n",
    "test[\"dt_dayofweek\"] = test[\"dt_of_fr\"].dt.dayofweek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "년, 월, 일, 시, 분, 초를 기준으로 화재 발생 건수를 확인할 필요가 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.shape)\n",
    "print(val.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_fire = train[['dt_year', 'fr_yn']]\n",
    "year_fire = year_fire[year_fire.fr_yn != 'N']\n",
    "year_fire = year_fire[\"dt_year\"].value_counts().rename_axis('year').reset_index(name='fire_Yes')\n",
    "year_fire = year_fire.sort_values([\"year\"], ascending=[True])\n",
    "year_fire.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_fire = train[['dt_month', 'fr_yn']]\n",
    "month_fire = month_fire[month_fire.fr_yn != 'N']\n",
    "month_fire = month_fire[\"dt_month\"].value_counts().rename_axis('month').reset_index(name='fire_Yes')\n",
    "month_fire = month_fire.sort_values([\"month\"], ascending=[True])\n",
    "month_fire.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_fire = train[['dt_day', 'fr_yn']]\n",
    "day_fire = day_fire[day_fire.fr_yn != 'N']\n",
    "day_fire = day_fire[\"dt_day\"].value_counts().rename_axis('day').reset_index(name='fire_Yes')\n",
    "day_fire = day_fire.sort_values([\"day\"], ascending=[True])\n",
    "day_fire.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hour_fire = train[['dt_hour', 'fr_yn']]\n",
    "hour_fire = hour_fire[hour_fire.fr_yn != 'N']\n",
    "hour_fire = hour_fire[\"dt_hour\"].value_counts().rename_axis('hour').reset_index(name='fire_Yes')\n",
    "hour_fire = hour_fire.sort_values([\"hour\"], ascending=[True])\n",
    "hour_fire.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minute_fire = train[['dt_minute', 'fr_yn']]\n",
    "minute_fire = minute_fire[minute_fire.fr_yn != 'N']\n",
    "minute_fire = minute_fire[\"dt_minute\"].value_counts().rename_axis('minute').reset_index(name='fire_Yes')\n",
    "minute_fire = minute_fire.sort_values([\"minute\"], ascending=[True])\n",
    "minute_fire.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore with visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# seaborn의 barplot으로, subplots의 각 구역에 연, 월, 일, 시, 별 화재 발생 건수를 출력\n",
    "\n",
    "# 2x2, 총 4개의 시각화를 한 화면에 띄우기\n",
    "figure, ((ax1, ax2), (ax3, ax4)) = plt.subplots(nrows=2, ncols=2)\n",
    "\n",
    "# 시각화의 전체 사이즈는 18x12로 설정\n",
    "figure.set_size_inches(18, 12)\n",
    "\n",
    "sns.barplot(data=year_fire, x=\"year\", y=\"fire_Yes\", ax=ax1)\n",
    "sns.barplot(data=month_fire, x=\"month\", y=\"fire_Yes\", ax=ax2)\n",
    "sns.barplot(data=day_fire, x=\"day\", y=\"fire_Yes\", ax=ax3)\n",
    "sns.barplot(data=hour_fire, x=\"hour\", y=\"fire_Yes\", ax=ax4)\n",
    "\n",
    "# seaborn의 barplot으로 분 별 화재 발생 건수를 출력\n",
    "figure, ax5 = plt.subplots(nrows=1, ncols=1)\n",
    "figure.set_size_inches(18, 4)\n",
    "sns.barplot(data=minute_fire, x=\"minute\", y=\"fire_Yes\", ax=ax5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 막대그래프를 통해 알 수 있는 내용은 다음과 같다.\n",
    "\n",
    "#### year\n",
    "* 2015년도에 가장 많은 화재가 발생했고 가장 적게 화재가 발생한 2018년과 발생 횟수가 상당히 차이나는 것을 볼 수 있다.<br>\n",
    "* 그렇지만 연도별 화재 발생 건수에 대한 막대그래프에서 일정한 추세를 확인할 수는 없었다.<br>\n",
    "* 2015년도와 2017년도가 다른 해에 비해 왜 더 많은 화재가 발생했는지 확인할 수 있다면 그것을 확인해야 할 것이며,<br>\n",
    "  그렇지 못 하다면 연도별 화재 발생 건수는 분석에 도움이 되지 않을 것으로 보인다.\n",
    "\n",
    "#### month\n",
    "* 겨울에서 초봄(12월-3월)사이에 가장 많이 화재가 발생했으며, 여름에서 늦여름(6-9월)까지는 비교적 화재 발생 건수가 적다.\n",
    "* 5월과 10월, 11월 또한 여름에 비해 화재 발생 건수가 많다. 한창 건조할 봄과 가을이기 때문일 것이다.\n",
    "\n",
    "#### day\n",
    "* 월 초와 월 중반이 다른 때에 비해 화재 발생 건수가 많은 것을 확인할 수 있다.\n",
    "* 그 외의 특정한 추세는 보이지 않으나 31일이 유난히 화재 발생 건수가 적었다.<br>\n",
    "  당연한 것이, 1년 중 1월, 3월, 5월, 7월, 8월, 10월, 12월만 31일이 있기 때문이다. 크게 문제가 될 것 같진 않아 보인다.\n",
    "\n",
    "#### hour\n",
    "* 사람들이 많이 활동하는 시간일수록 화재 발생 건수가 많아지는 추세를 보인다.\n",
    "\n",
    "\n",
    "#### minute\n",
    "* 특별한 추세가 보이지 않는다.\n",
    "\n",
    "\n",
    "#### second\n",
    "* 화재가 발생한 '초'는 전부 0으로 기록되어 있다. 공모전 주최측에서 second는 활용하지 말라고 하였기에 분석 대상에서 제외한다.\n",
    "\n",
    "#### <font color=\"red\">결론 : day는 의미없는 데이터로 보이나 일단은 먼저 앙상블 모델에 투입한다. 이후 day를 제거한 모델을 새로 만들어보기로 하자.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <del>Parse district</del> \n",
    "<font color='red'>지역은 구분하지 않기로 확정</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"emd_nm_1\"] = train.emd_nm.str.split(' ').str[0]\n",
    "train[\"emd_nm_2\"] = train.emd_nm.str.split(' ').str[1]\n",
    "train[\"emd_nm_3\"] = train.emd_nm.str.split(' ').str[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[['emd_nm_1', 'emd_nm_2', 'emd_nm_3']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['emd_nm_1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train['emd_nm_2'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train['emd_nm_3'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 앙상블 모델에 emd_nm은 쓰지 않도록 하며, emd_nm_1 은 전부 '경상남도'이므로 모델에 적용하지 않도록 한다.\n",
    "train = train.drop(['emd_nm', 'emd_nm_1'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation dataset과 test dataset에도 동일한 작업을 진행\n",
    "\n",
    "val[\"emd_nm_1\"] = val.emd_nm.str.split(' ').str[0]\n",
    "val[\"emd_nm_2\"] = val.emd_nm.str.split(' ').str[1]\n",
    "val[\"emd_nm_3\"] = val.emd_nm.str.split(' ').str[2]\n",
    "val = val.drop(['emd_nm', 'emd_nm_1'], axis=1)\n",
    "\n",
    "test[\"emd_nm_1\"] = test.emd_nm.str.split(' ').str[0]\n",
    "test[\"emd_nm_2\"] = test.emd_nm.str.split(' ').str[1]\n",
    "test[\"emd_nm_3\"] = test.emd_nm.str.split(' ').str[2]\n",
    "test = test.drop(['emd_nm', 'emd_nm_1'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val[['emd_nm_2', 'emd_nm_3']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Feature Engineering</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 문자로 구성된 value를 binary 혹은 categorical 형태로 변형시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 화재 발생 여부를 나타내는 'fr_yn' column의 value들을 binary로 변환\n",
    "binary_y = {'N': 0, 'Y': 1}\n",
    "train['fr_yn'] = train['fr_yn'].map(binary_y)\n",
    "val['fr_yn'] = val['fr_yn'].map(binary_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train['fr_yn'].head())\n",
    "print()\n",
    "print(val['fr_yn'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 범주형 변수들을 one-hot encoding 방식으로 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train.shape)\n",
    "print(val.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    " # train, val, test를 세로로 아래로 합치기\n",
    "df_all = pd.concat([train, val, test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['bldng_archtctr', 'bldng_us', 'bldng_us_clssfctn',\n",
       "       'blk_dngrs_thng_mnfctr_yn', 'cltrl_hrtg_yn', 'dngrs_thng_yn',\n",
       "       'dt_of_athrztn', 'emd_nm', 'fr_fghtng_fclt_spcl_css_5_yn',\n",
       "       'fr_fghtng_fclt_spcl_css_6_yn', 'jmk', 'lnd_us_sttn_nm', 'mlt_us_yn',\n",
       "       'rd_sd_nm', 'rgnl_ar_nm', 'rgnl_ar_nm2', 'slf_fr_brgd_yn', 'trgt_crtr',\n",
       "       'us_yn'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 컬럼 data type 중 'object'인 것들만 추려내어 컬럼명으로 리스트 만들기\n",
    "categorical_cols = df_all.select_dtypes(['object']).columns\n",
    "categorical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data type이 'object'인 각 column을 돌며 value값들을 categorical variable로 변환\n",
    "for col in categorical_cols:\n",
    "    df_all[col] = pd.Categorical(df_all[col]).codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다시 train, val, test로 잘라내기\n",
    "train = df_all[:len(train)]\n",
    "val = df_all[len(train):-len(test)]\n",
    "test = df_all[-len(test):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. X_train, y_train, X_val, y_val, test dataframe 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(['fr_yn', 'dt_of_fr', 'id'], 1) # train에서 'fr_yn', 'dt_of_fr', 'id' column을 drop\n",
    "y_train = train['fr_yn']\n",
    "X_val = val.drop(['fr_yn', 'dt_of_fr', 'id'], 1) # val에서 'fr_yn', 'dt_of_fr', 'id' column을 drop\n",
    "y_val = val['fr_yn']\n",
    "test = test.drop(['fr_yn', 'dt_of_fr', 'id'], 1) # test에서 'fr_yn', dt_of_fr', 'id' column을 drop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 각 dataframe의 결측치를 column의 평균값으로 채우기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측치를 가진 row를 제거하는 방식은 X_train의 모든 row를 제거해버리기 때문에 불가능하다.\n",
    "# 결측치를 column의 평균으로 채운 방식을 활용하도록 한다.\n",
    "X_train = X_train.fillna(X_train.mean()) \n",
    "X_val = X_val.fillna(X_val.mean()) \n",
    "test = test.fillna(test.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "random forest 모델의 파라미터 중 가장 중요한 것은 n_estimators와 max_features이다.<br>\n",
    "n_estimators(앙상블을 구성하는 의사 결정 나무의 개수)는 충분히 크게 설정하여도 과 적합(Overfit) 문제가 발생하기 않기 때문에 가능한 한 크게 설정하며,<br>\n",
    "max_features(랜덤하게 선택되는 변수의 개수)는 변수의 개수의 제곱근을 이용하는 것이 가장 좋다고 알려져있다.(Breiman, 2001; 2002)<br>\n",
    "다만 max_features는 int형이어야 하므로 변수의 개수의 제곱근에 round 함수를 이용하여 int형으로 바꿔주도록 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_2000 = RandomForestClassifier(n_jobs=-1, n_estimators=2000, random_state=42, max_features=round(math.sqrt(len(X_train.columns))))\n",
    "forest_2000.fit(X_train, y_train)\n",
    "y_pred = forest_2000.predict(X_val)\n",
    "print('f1 score :', f1_score(y_val, y_pred))\n",
    "print('accuracy :', accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Prediction</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = forest_2000.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictions.shape)\n",
    "predictions[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(model, X_train, figsize=(12, 6)):\n",
    "    sns.set_style('darkgrid')\n",
    "    \n",
    "    # Plot feature importance\n",
    "    feature_importance = model.feature_importances_\n",
    "    feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "    sorted_idx = np.argsort(feature_importance)\n",
    "    pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "    plt.yticks(pos, X_train.columns[sorted_idx])\n",
    "    plt.xlabel('Relative Importance')\n",
    "    plt.title('Variable Importance')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_importance(forest_2000, X_train, (10, 35))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Prediction</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['fr_yn'] = predictions\n",
    "sub['fr_yn'] = sub['fr_yn'].map({0:'N', 1:'Y'})\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('yhw8258_화재예측과제_Submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='red'>Train & Evaluate</font> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 변수에서 fr_yn, dt_of_fr, id, emd_nm을 버렸을 때의 모델 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators_10to100 = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "n_estimators_200to1000 = [200, 300, 400, 500, 600, 700, 800, 900, 1000]\n",
    "n_estimators_1100to2000 = [1100, 1200, 1300, 1400, 1500, 1600, 1700, 1800, 1900, 2000]\n",
    "\n",
    "list_f1 = []\n",
    "list_ac = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators가 10-100 사이에서의 결과\n",
      "\n",
      "n_estimators = 10 일때 f1 score = 0.42673107890499196\n",
      "n_estimators = 20 일때 f1 score = 0.455779514603044\n",
      "n_estimators = 30 일때 f1 score = 0.4853969559851913\n",
      "n_estimators = 40 일때 f1 score = 0.49324047521507575\n",
      "n_estimators = 50 일때 f1 score = 0.45894263217097864\n",
      "n_estimators = 60 일때 f1 score = 0.48152562574493446\n",
      "n_estimators = 70 일때 f1 score = 0.48603351955307256\n",
      "n_estimators = 80 일때 f1 score = 0.5028571428571429\n",
      "n_estimators = 90 일때 f1 score = 0.5020441537203598\n",
      "n_estimators = 100 일때 f1 score = 0.5010250102501024\n",
      "\n",
      "n_estimators = 10 일때 accuracy = 0.7935633516961438\n",
      "n_estimators = 20 일때 accuracy = 0.8082052768918527\n",
      "n_estimators = 30 일때 accuracy = 0.8186430849521601\n",
      "n_estimators = 40 일때 accuracy = 0.8206726587416643\n",
      "n_estimators = 50 일때 accuracy = 0.7908089301246738\n",
      "n_estimators = 60 일때 accuracy = 0.8108147289069295\n",
      "n_estimators = 70 일때 accuracy = 0.8132792113656132\n",
      "n_estimators = 80 일때 accuracy = 0.8234270803131343\n",
      "n_estimators = 90 일때 accuracy = 0.8234270803131343\n",
      "n_estimators = 100 일때 accuracy = 0.8235720498695274\n",
      "\n",
      "가장 좋은 f1 score를 가지는 n_estimator는 80 이며,\n",
      "그 값은 f1_score = 0.5028571428571429 입니다.\n",
      "\n",
      "가장 좋은 accucracy를 가지는 n_estimator는 100 입니다.\n",
      "그 값은 accuracy = 0.8235720498695274 입니다.\n"
     ]
    }
   ],
   "source": [
    "list_f1_10to100 = []\n",
    "list_ac_10to100 = []\n",
    "\n",
    "for elem in n_estimators_10to100:\n",
    "    forest = RandomForestClassifier(n_jobs=-1, n_estimators=elem, random_state=42, max_features=round(math.sqrt(len(X_train.columns))))\n",
    "    forest.fit(X_train, y_train)\n",
    "    y_pred = forest.predict(X_val)\n",
    "    list_f1_10to100.append(f1_score(y_val, y_pred))\n",
    "    list_ac_10to100.append(accuracy_score(y_val, y_pred))\n",
    "\n",
    "list_f1 = list_f1 + list_f1_10to100\n",
    "list_ac = list_ac + list_ac_10to100\n",
    "\n",
    "best_f1_score = -999999\n",
    "best_f1_score_of_index = 0\n",
    "best_accuracy = -999999\n",
    "best_accuracy_of_index = 0\n",
    "\n",
    "print('n_estimators가 10-100 사이에서의 결과\\n')\n",
    "\n",
    "tmp = 0\n",
    "for i in n_estimators_10to100:\n",
    "    print('n_estimators =', i, '일때 f1 score =', list_f1_10to100[tmp])\n",
    "    tmp = tmp + 1\n",
    "\n",
    "print()\n",
    "\n",
    "tmp = 0\n",
    "for i in n_estimators_10to100:\n",
    "    print('n_estimators =', i, '일때 accuracy =', list_ac_10to100[tmp])\n",
    "    tmp = tmp + 1\n",
    "    \n",
    "tmp = -1\n",
    "for i in list_f1_10to100:\n",
    "    tmp = tmp + 1\n",
    "    if best_f1_score < i:\n",
    "        best_f1_score = i\n",
    "        best_f1_score_of_index = tmp\n",
    "\n",
    "print()\n",
    "print('가장 좋은 f1 score를 가지는 n_estimator는', n_estimators_10to100[best_f1_score_of_index], '이며,')\n",
    "print('그 값은 f1_score =', best_f1_score, '입니다.')\n",
    "\n",
    "tmp = -1\n",
    "for i in list_ac_10to100:\n",
    "    tmp = tmp + 1\n",
    "    if best_accuracy < i:\n",
    "        best_accuracy = i\n",
    "        best_accuracy_of_index = tmp\n",
    "      \n",
    "print()\n",
    "print('가장 좋은 accucracy를 가지는 n_estimator는', n_estimators_10to100[best_accuracy_of_index], '입니다.')\n",
    "print('그 값은 accuracy =', best_accuracy, '입니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators가 200-1000 사이에서의 결과\n",
      "\n",
      "n_estimators = 200 일때 f1 score = 0.49854832019908746\n",
      "n_estimators = 300 일때 f1 score = 0.5041322314049587\n",
      "n_estimators = 400 일때 f1 score = 0.5020610057708161\n",
      "n_estimators = 500 일때 f1 score = 0.5020712510356256\n",
      "n_estimators = 600 일때 f1 score = 0.506255212677231\n",
      "n_estimators = 700 일때 f1 score = 0.5050251256281406\n",
      "n_estimators = 800 일때 f1 score = 0.5056414542415377\n",
      "n_estimators = 900 일때 f1 score = 0.5033557046979866\n",
      "n_estimators = 1000 일때 f1 score = 0.5060949978982766\n",
      "\n",
      "n_estimators = 200 일때 accuracy = 0.8247318063206727\n",
      "n_estimators = 300 일때 accuracy = 0.8260365323282111\n",
      "n_estimators = 400 일때 accuracy = 0.8248767758770659\n",
      "n_estimators = 500 일때 accuracy = 0.8257465932154248\n",
      "n_estimators = 600 일때 accuracy = 0.8283560452305015\n",
      "n_estimators = 700 일때 accuracy = 0.828645984343288\n",
      "n_estimators = 800 일때 accuracy = 0.8285010147868948\n",
      "n_estimators = 900 일때 accuracy = 0.8283560452305015\n",
      "n_estimators = 1000 일때 accuracy = 0.82966077123804\n",
      "\n",
      "가장 좋은 f1 score를 가지는 n_estimator는 600 이며,\n",
      "그 값은 f1_score = 0.506255212677231 입니다.\n",
      "\n",
      "가장 좋은 accucracy를 가지는 n_estimator는 1000 입니다.\n",
      "그 값은 accuracy = 0.82966077123804 입니다.\n"
     ]
    }
   ],
   "source": [
    "list_f1_200to1000 = []\n",
    "list_ac_200to1000 = []\n",
    "\n",
    "for elem in n_estimators_200to1000:\n",
    "    forest = RandomForestClassifier(n_jobs=-1, n_estimators=elem, random_state=42, max_features=round(math.sqrt(len(X_train.columns))))\n",
    "    forest.fit(X_train, y_train)\n",
    "    y_pred = forest.predict(X_val)\n",
    "    list_f1_200to1000.append(f1_score(y_val, y_pred))\n",
    "    list_ac_200to1000.append(accuracy_score(y_val, y_pred))\n",
    "\n",
    "list_f1 = list_f1 + list_f1_200to1000\n",
    "list_ac = list_ac + list_ac_200to1000\n",
    "\n",
    "best_f1_score = -999999\n",
    "best_f1_score_of_index = 0\n",
    "best_accuracy = -999999\n",
    "best_accuracy_of_index = 0\n",
    "\n",
    "print('n_estimators가 200-1000 사이에서의 결과\\n')\n",
    "\n",
    "tmp = 0\n",
    "for i in n_estimators_200to1000:\n",
    "    print('n_estimators =', i, '일때 f1 score =', list_f1_200to1000[tmp])\n",
    "    tmp = tmp + 1\n",
    "\n",
    "print()\n",
    "\n",
    "tmp = 0\n",
    "for i in n_estimators_200to1000:\n",
    "    print('n_estimators =', i, '일때 accuracy =', list_ac_200to1000[tmp])\n",
    "    tmp = tmp + 1\n",
    "    \n",
    "tmp = -1\n",
    "for i in list_f1_200to1000:\n",
    "    tmp = tmp + 1\n",
    "    if best_f1_score < i:\n",
    "        best_f1_score = i\n",
    "        best_f1_score_of_index = tmp\n",
    "\n",
    "print()\n",
    "print('가장 좋은 f1 score를 가지는 n_estimator는', n_estimators_200to1000[best_f1_score_of_index], '이며,')\n",
    "print('그 값은 f1_score =', best_f1_score, '입니다.')\n",
    "\n",
    "tmp = -1\n",
    "for i in list_ac_200to1000:\n",
    "    tmp = tmp + 1\n",
    "    if best_accuracy < i:\n",
    "        best_accuracy = i\n",
    "        best_accuracy_of_index = tmp\n",
    "      \n",
    "print()\n",
    "print('가장 좋은 accucracy를 가지는 n_estimator는', n_estimators_200to1000[best_accuracy_of_index], '입니다.')\n",
    "print('그 값은 accuracy =', best_accuracy, '입니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators가 1100-2000 사이에서의 결과\n",
      "\n",
      "n_estimators = 1100 일때 f1 score = 0.5073252406864797\n",
      "n_estimators = 1200 일때 f1 score = 0.5085881860075409\n",
      "n_estimators = 1300 일때 f1 score = 0.5064989517819707\n",
      "n_estimators = 1400 일때 f1 score = 0.5035789473684211\n",
      "n_estimators = 1500 일때 f1 score = 0.5037846930193439\n",
      "n_estimators = 1600 일때 f1 score = 0.5031552376945729\n",
      "n_estimators = 1700 일때 f1 score = 0.5037783375314862\n",
      "n_estimators = 1800 일때 f1 score = 0.5039899202015959\n",
      "n_estimators = 1900 일때 f1 score = 0.5039899202015959\n",
      "n_estimators = 2000 일때 f1 score = 0.5037720033528919\n",
      "\n",
      "n_estimators = 1100 일때 accuracy = 0.8293708321252536\n",
      "n_estimators = 1200 일때 accuracy = 0.8299507103508263\n",
      "n_estimators = 1300 일때 accuracy = 0.8293708321252536\n",
      "n_estimators = 1400 일때 accuracy = 0.8290808930124673\n",
      "n_estimators = 1500 일때 accuracy = 0.8289359234560743\n",
      "n_estimators = 1600 일때 accuracy = 0.828790953899681\n",
      "n_estimators = 1700 일때 accuracy = 0.828645984343288\n",
      "n_estimators = 1800 일때 accuracy = 0.828790953899681\n",
      "n_estimators = 1900 일때 accuracy = 0.828790953899681\n",
      "n_estimators = 2000 일때 accuracy = 0.8283560452305015\n",
      "\n",
      "가장 좋은 f1 score를 가지는 n_estimator는 1200 이며,\n",
      "그 값은 f1_score = 0.5085881860075409 입니다.\n",
      "\n",
      "가장 좋은 accucracy를 가지는 n_estimator는 1200 입니다.\n",
      "그 값은 accuracy = 0.8299507103508263 입니다.\n"
     ]
    }
   ],
   "source": [
    "list_f1_1100to2000 = []\n",
    "list_ac_1100to2000 = []\n",
    "\n",
    "for elem in n_estimators_1100to2000:\n",
    "    forest = RandomForestClassifier(n_jobs=-1, n_estimators=elem, random_state=42, max_features=round(math.sqrt(len(X_train.columns))))\n",
    "    forest.fit(X_train, y_train)\n",
    "    y_pred = forest.predict(X_val)\n",
    "    list_f1_1100to2000.append(f1_score(y_val, y_pred))\n",
    "    list_ac_1100to2000.append(accuracy_score(y_val, y_pred))\n",
    "\n",
    "list_f1 = list_f1 + list_f1_1100to2000\n",
    "list_ac = list_ac + list_ac_1100to2000\n",
    "\n",
    "best_f1_score = -999999\n",
    "best_f1_score_of_index = 0\n",
    "best_accuracy = -999999\n",
    "best_accuracy_of_index = 0\n",
    "\n",
    "print('n_estimators가 1100-2000 사이에서의 결과\\n')\n",
    "\n",
    "tmp = 0\n",
    "for i in n_estimators_1100to2000:\n",
    "    print('n_estimators =', i, '일때 f1 score =', list_f1_1100to2000[tmp])\n",
    "    tmp = tmp + 1\n",
    "\n",
    "print()\n",
    "\n",
    "tmp = 0\n",
    "for i in n_estimators_1100to2000:\n",
    "    print('n_estimators =', i, '일때 accuracy =', list_ac_1100to2000[tmp])\n",
    "    tmp = tmp + 1\n",
    "    \n",
    "tmp = -1\n",
    "for i in list_f1_1100to2000:\n",
    "    tmp = tmp + 1\n",
    "    if best_f1_score < i:\n",
    "        best_f1_score = i\n",
    "        best_f1_score_of_index = tmp\n",
    "\n",
    "print()\n",
    "print('가장 좋은 f1 score를 가지는 n_estimator는', n_estimators_1100to2000[best_f1_score_of_index], '이며,')\n",
    "print('그 값은 f1_score =', best_f1_score, '입니다.')\n",
    "\n",
    "tmp = -1\n",
    "for i in list_ac_1100to2000:\n",
    "    tmp = tmp + 1\n",
    "    if best_accuracy < i:\n",
    "        best_accuracy = i\n",
    "        best_accuracy_of_index = tmp\n",
    "      \n",
    "print()\n",
    "print('가장 좋은 accucracy를 가지는 n_estimator는', n_estimators_1100to2000[best_accuracy_of_index], '입니다.')\n",
    "print('그 값은 accuracy =', best_accuracy, '입니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가장 좋은 모델은 n_estimators = 1200 이며\n",
      "그때의 f1_score = 0.5085881860075409 이다.\n"
     ]
    }
   ],
   "source": [
    "tmp = 0\n",
    "\n",
    "for i in list_f1:\n",
    "    if i > tmp:\n",
    "        tmp = i\n",
    "\n",
    "x = list_f1.index(tmp)\n",
    "\n",
    "if x <= 10:\n",
    "    best_f1 = list_f1_10to100[x]\n",
    "    best_n = n_estimators_10to100[x]\n",
    "elif x <= 19:\n",
    "    x = x - 10\n",
    "    best_f1 = list_f1_200to1000[x]\n",
    "    best_n = n_estimators_200to1000[x]\n",
    "elif x <= 29:\n",
    "    x = x - 19\n",
    "    best_f1 = list_f1_1100to2000[x]\n",
    "    best_n = n_estimators_1100to2000[x]\n",
    "\n",
    "print('가장 좋은 모델은 n_estimators =', best_n, '이며')\n",
    "print('그때의 f1_score =', best_f1, '이다.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 변수에서 fr_yn, dt_of_fr, id를 버리고 emd_nm을 버리지 않았을 때의 모델 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators_10to100 = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "n_estimators_200to1000 = [200, 300, 400, 500, 600, 700, 800, 900, 1000]\n",
    "n_estimators_1100to2000 = [1100, 1200, 1300, 1400, 1500, 1600, 1700, 1800, 1900, 2000]\n",
    "\n",
    "list_f1 = []\n",
    "list_ac = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators가 10-100 사이에서의 결과\n",
      "\n",
      "n_estimators = 10 일때 f1 score = 0.45123839009287925\n",
      "n_estimators = 20 일때 f1 score = 0.4786729857819905\n",
      "n_estimators = 30 일때 f1 score = 0.49563838223632034\n",
      "n_estimators = 40 일때 f1 score = 0.5020080321285141\n",
      "n_estimators = 50 일때 f1 score = 0.4985904148207813\n",
      "n_estimators = 60 일때 f1 score = 0.5063897763578276\n",
      "n_estimators = 70 일때 f1 score = 0.5014129995962858\n",
      "n_estimators = 80 일때 f1 score = 0.5075602778912955\n",
      "n_estimators = 90 일때 f1 score = 0.5159209995969367\n",
      "n_estimators = 100 일때 f1 score = 0.5080385852090032\n",
      "\n",
      "n_estimators = 10 일때 accuracy = 0.7944331690345028\n",
      "n_estimators = 20 일때 accuracy = 0.8086401855610322\n",
      "n_estimators = 30 일때 accuracy = 0.8155987242679037\n",
      "n_estimators = 40 일때 accuracy = 0.8202377500724848\n",
      "n_estimators = 50 일때 accuracy = 0.819512902290519\n",
      "n_estimators = 60 일때 accuracy = 0.8208176282980574\n",
      "n_estimators = 70 일때 accuracy = 0.8209625978544506\n",
      "n_estimators = 80 일때 accuracy = 0.8253116845462453\n",
      "n_estimators = 90 일때 accuracy = 0.825891562771818\n",
      "n_estimators = 100 일때 accuracy = 0.8225572629747753\n",
      "\n",
      "가장 좋은 f1 score를 가지는 n_estimator는 90 이며,\n",
      "그 값은 f1_score = 0.5159209995969367 입니다.\n",
      "\n",
      "가장 좋은 accucracy를 가지는 n_estimator는 90 입니다.\n",
      "그 값은 accuracy = 0.825891562771818 입니다.\n"
     ]
    }
   ],
   "source": [
    "list_f1_10to100 = []\n",
    "list_ac_10to100 = []\n",
    "\n",
    "for elem in n_estimators_10to100:\n",
    "    forest = RandomForestClassifier(n_jobs=-1, n_estimators=elem, random_state=42, max_features=round(math.sqrt(len(X_train.columns))))\n",
    "    forest.fit(X_train, y_train)\n",
    "    y_pred = forest.predict(X_val)\n",
    "    list_f1_10to100.append(f1_score(y_val, y_pred))\n",
    "    list_ac_10to100.append(accuracy_score(y_val, y_pred))\n",
    "\n",
    "list_f1 = list_f1 + list_f1_10to100\n",
    "list_ac = list_ac + list_ac_10to100\n",
    "\n",
    "best_f1_score = -999999\n",
    "best_f1_score_of_index = 0\n",
    "best_accuracy = -999999\n",
    "best_accuracy_of_index = 0\n",
    "\n",
    "print('n_estimators가 10-100 사이에서의 결과\\n')\n",
    "\n",
    "tmp = 0\n",
    "for i in n_estimators_10to100:\n",
    "    print('n_estimators =', i, '일때 f1 score =', list_f1_10to100[tmp])\n",
    "    tmp = tmp + 1\n",
    "\n",
    "print()\n",
    "\n",
    "tmp = 0\n",
    "for i in n_estimators_10to100:\n",
    "    print('n_estimators =', i, '일때 accuracy =', list_ac_10to100[tmp])\n",
    "    tmp = tmp + 1\n",
    "    \n",
    "tmp = -1\n",
    "for i in list_f1_10to100:\n",
    "    tmp = tmp + 1\n",
    "    if best_f1_score < i:\n",
    "        best_f1_score = i\n",
    "        best_f1_score_of_index = tmp\n",
    "\n",
    "print()\n",
    "print('가장 좋은 f1 score를 가지는 n_estimator는', n_estimators_10to100[best_f1_score_of_index], '이며,')\n",
    "print('그 값은 f1_score =', best_f1_score, '입니다.')\n",
    "\n",
    "tmp = -1\n",
    "for i in list_ac_10to100:\n",
    "    tmp = tmp + 1\n",
    "    if best_accuracy < i:\n",
    "        best_accuracy = i\n",
    "        best_accuracy_of_index = tmp\n",
    "      \n",
    "print()\n",
    "print('가장 좋은 accucracy를 가지는 n_estimator는', n_estimators_10to100[best_accuracy_of_index], '입니다.')\n",
    "print('그 값은 accuracy =', best_accuracy, '입니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators가 200-1000 사이에서의 결과\n",
      "\n",
      "n_estimators = 200 일때 f1 score = 0.5057562524811433\n",
      "n_estimators = 300 일때 f1 score = 0.5097244732576984\n",
      "n_estimators = 400 일때 f1 score = 0.5048780487804878\n",
      "n_estimators = 500 일때 f1 score = 0.511552492906364\n",
      "n_estimators = 600 일때 f1 score = 0.5097087378640777\n",
      "n_estimators = 700 일때 f1 score = 0.5064724919093851\n",
      "n_estimators = 800 일때 f1 score = 0.5103280680437424\n",
      "n_estimators = 900 일때 f1 score = 0.509979633401222\n",
      "n_estimators = 1000 일때 f1 score = 0.5105691056910568\n",
      "\n",
      "n_estimators = 200 일때 accuracy = 0.819512902290519\n",
      "n_estimators = 300 일때 accuracy = 0.8245868367642795\n",
      "n_estimators = 400 일때 accuracy = 0.8234270803131343\n",
      "n_estimators = 500 일때 accuracy = 0.8253116845462453\n",
      "n_estimators = 600 일때 accuracy = 0.8242968976514932\n",
      "n_estimators = 700 일때 accuracy = 0.823137141200348\n",
      "n_estimators = 800 일때 accuracy = 0.8247318063206727\n",
      "n_estimators = 900 일때 accuracy = 0.8256016236590316\n",
      "n_estimators = 1000 일때 accuracy = 0.8254566541026385\n",
      "\n",
      "가장 좋은 f1 score를 가지는 n_estimator는 500 이며,\n",
      "그 값은 f1_score = 0.511552492906364 입니다.\n",
      "\n",
      "가장 좋은 accucracy를 가지는 n_estimator는 900 입니다.\n",
      "그 값은 accuracy = 0.8256016236590316 입니다.\n"
     ]
    }
   ],
   "source": [
    "list_f1_200to1000 = []\n",
    "list_ac_200to1000 = []\n",
    "\n",
    "for elem in n_estimators_200to1000:\n",
    "    forest = RandomForestClassifier(n_jobs=-1, n_estimators=elem, random_state=42, max_features=round(math.sqrt(len(X_train.columns))))\n",
    "    forest.fit(X_train, y_train)\n",
    "    y_pred = forest.predict(X_val)\n",
    "    list_f1_200to1000.append(f1_score(y_val, y_pred))\n",
    "    list_ac_200to1000.append(accuracy_score(y_val, y_pred))\n",
    "\n",
    "list_f1 = list_f1 + list_f1_200to1000\n",
    "list_ac = list_ac + list_ac_200to1000\n",
    "\n",
    "best_f1_score = -999999\n",
    "best_f1_score_of_index = 0\n",
    "best_accuracy = -999999\n",
    "best_accuracy_of_index = 0\n",
    "\n",
    "print('n_estimators가 200-1000 사이에서의 결과\\n')\n",
    "\n",
    "tmp = 0\n",
    "for i in n_estimators_200to1000:\n",
    "    print('n_estimators =', i, '일때 f1 score =', list_f1_200to1000[tmp])\n",
    "    tmp = tmp + 1\n",
    "\n",
    "print()\n",
    "\n",
    "tmp = 0\n",
    "for i in n_estimators_200to1000:\n",
    "    print('n_estimators =', i, '일때 accuracy =', list_ac_200to1000[tmp])\n",
    "    tmp = tmp + 1\n",
    "    \n",
    "tmp = -1\n",
    "for i in list_f1_200to1000:\n",
    "    tmp = tmp + 1\n",
    "    if best_f1_score < i:\n",
    "        best_f1_score = i\n",
    "        best_f1_score_of_index = tmp\n",
    "\n",
    "print()\n",
    "print('가장 좋은 f1 score를 가지는 n_estimator는', n_estimators_200to1000[best_f1_score_of_index], '이며,')\n",
    "print('그 값은 f1_score =', best_f1_score, '입니다.')\n",
    "\n",
    "tmp = -1\n",
    "for i in list_ac_200to1000:\n",
    "    tmp = tmp + 1\n",
    "    if best_accuracy < i:\n",
    "        best_accuracy = i\n",
    "        best_accuracy_of_index = tmp\n",
    "      \n",
    "print()\n",
    "print('가장 좋은 accucracy를 가지는 n_estimator는', n_estimators_200to1000[best_accuracy_of_index], '입니다.')\n",
    "print('그 값은 accuracy =', best_accuracy, '입니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators가 1100-2000 사이에서의 결과\n",
      "\n",
      "n_estimators = 1100 일때 f1 score = 0.5117982099267696\n",
      "n_estimators = 1200 일때 f1 score = 0.5119869971556278\n",
      "n_estimators = 1300 일때 f1 score = 0.5107767385115901\n",
      "n_estimators = 1400 일때 f1 score = 0.511002444987775\n",
      "n_estimators = 1500 일때 f1 score = 0.5147058823529411\n",
      "n_estimators = 1600 일때 f1 score = 0.5134914145543744\n",
      "n_estimators = 1700 일때 f1 score = 0.513888888888889\n",
      "n_estimators = 1800 일때 f1 score = 0.5136567468406033\n",
      "n_estimators = 1900 일때 f1 score = 0.5144720750101915\n",
      "n_estimators = 2000 일때 f1 score = 0.5126118795768918\n",
      "\n",
      "n_estimators = 1100 일때 accuracy = 0.8260365323282111\n",
      "n_estimators = 1200 일때 accuracy = 0.825891562771818\n",
      "n_estimators = 1300 일때 accuracy = 0.8256016236590316\n",
      "n_estimators = 1400 일때 accuracy = 0.8260365323282111\n",
      "n_estimators = 1500 일때 accuracy = 0.827776167004929\n",
      "n_estimators = 1600 일때 accuracy = 0.8274862278921427\n",
      "n_estimators = 1700 일때 accuracy = 0.8274862278921427\n",
      "n_estimators = 1800 일때 accuracy = 0.8270513192229632\n",
      "n_estimators = 1900 일때 accuracy = 0.8273412583357495\n",
      "n_estimators = 2000 일때 accuracy = 0.8263264714409974\n",
      "\n",
      "가장 좋은 f1 score를 가지는 n_estimator는 1500 이며,\n",
      "그 값은 f1_score = 0.5147058823529411 입니다.\n",
      "\n",
      "가장 좋은 accucracy를 가지는 n_estimator는 1500 입니다.\n",
      "그 값은 accuracy = 0.827776167004929 입니다.\n"
     ]
    }
   ],
   "source": [
    "list_f1_1100to2000 = []\n",
    "list_ac_1100to2000 = []\n",
    "\n",
    "for elem in n_estimators_1100to2000:\n",
    "    forest = RandomForestClassifier(n_jobs=-1, n_estimators=elem, random_state=42, max_features=round(math.sqrt(len(X_train.columns))))\n",
    "    forest.fit(X_train, y_train)\n",
    "    y_pred = forest.predict(X_val)\n",
    "    list_f1_1100to2000.append(f1_score(y_val, y_pred))\n",
    "    list_ac_1100to2000.append(accuracy_score(y_val, y_pred))\n",
    "\n",
    "list_f1 = list_f1 + list_f1_1100to2000\n",
    "list_ac = list_ac + list_ac_1100to2000\n",
    "\n",
    "best_f1_score = -999999\n",
    "best_f1_score_of_index = 0\n",
    "best_accuracy = -999999\n",
    "best_accuracy_of_index = 0\n",
    "\n",
    "print('n_estimators가 1100-2000 사이에서의 결과\\n')\n",
    "\n",
    "tmp = 0\n",
    "for i in n_estimators_1100to2000:\n",
    "    print('n_estimators =', i, '일때 f1 score =', list_f1_1100to2000[tmp])\n",
    "    tmp = tmp + 1\n",
    "\n",
    "print()\n",
    "\n",
    "tmp = 0\n",
    "for i in n_estimators_1100to2000:\n",
    "    print('n_estimators =', i, '일때 accuracy =', list_ac_1100to2000[tmp])\n",
    "    tmp = tmp + 1\n",
    "    \n",
    "tmp = -1\n",
    "for i in list_f1_1100to2000:\n",
    "    tmp = tmp + 1\n",
    "    if best_f1_score < i:\n",
    "        best_f1_score = i\n",
    "        best_f1_score_of_index = tmp\n",
    "\n",
    "print()\n",
    "print('가장 좋은 f1 score를 가지는 n_estimator는', n_estimators_1100to2000[best_f1_score_of_index], '이며,')\n",
    "print('그 값은 f1_score =', best_f1_score, '입니다.')\n",
    "\n",
    "tmp = -1\n",
    "for i in list_ac_1100to2000:\n",
    "    tmp = tmp + 1\n",
    "    if best_accuracy < i:\n",
    "        best_accuracy = i\n",
    "        best_accuracy_of_index = tmp\n",
    "      \n",
    "print()\n",
    "print('가장 좋은 accucracy를 가지는 n_estimator는', n_estimators_1100to2000[best_accuracy_of_index], '입니다.')\n",
    "print('그 값은 accuracy =', best_accuracy, '입니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가장 좋은 모델은 n_estimators = 90 이며\n",
      "그때의 f1_score = 0.5159209995969367 이다.\n"
     ]
    }
   ],
   "source": [
    "tmp = 0\n",
    "\n",
    "for i in list_f1:\n",
    "    if i > tmp:\n",
    "        tmp = i\n",
    "\n",
    "x = list_f1.index(tmp)\n",
    "\n",
    "if x <= 10:\n",
    "    best_f1 = list_f1_10to100[x]\n",
    "    best_n = n_estimators_10to100[x]\n",
    "elif x <= 19:\n",
    "    x = x - 10\n",
    "    best_f1 = list_f1_200to1000[x]\n",
    "    best_n = n_estimators_200to1000[x]\n",
    "elif x <= 29:\n",
    "    x = x - 19\n",
    "    best_f1 = list_f1_1100to2000[x]\n",
    "    best_n = n_estimators_1100to2000[x]\n",
    "\n",
    "print('가장 좋은 모델은 n_estimators =', best_n, '이며')\n",
    "print('그때의 f1_score =', best_f1, '이다.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 변수에서 fr_yn, dt_of_fr, id를 버렸고 emd_nm을 parse했을 때의 모델 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators_10to100 = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "n_estimators_200to1000 = [200, 300, 400, 500, 600, 700, 800, 900, 1000]\n",
    "n_estimators_1100to2000 = [1100, 1200, 1300, 1400, 1500, 1600, 1700, 1800, 1900, 2000]\n",
    "\n",
    "list_f1 = []\n",
    "list_ac = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators가 10-100 사이에서의 결과\n",
      "\n",
      "n_estimators = 10 일때 f1 score = 0.46396761133603237\n",
      "n_estimators = 20 일때 f1 score = 0.4604596805609661\n",
      "n_estimators = 30 일때 f1 score = 0.4814522494080505\n",
      "n_estimators = 40 일때 f1 score = 0.4818218138234119\n",
      "n_estimators = 50 일때 f1 score = 0.4822638501394978\n",
      "n_estimators = 60 일때 f1 score = 0.48881789137380194\n",
      "n_estimators = 70 일때 f1 score = 0.49919871794871795\n",
      "n_estimators = 80 일때 f1 score = 0.4975767366720517\n",
      "n_estimators = 90 일때 f1 score = 0.4989890820865346\n",
      "n_estimators = 100 일때 f1 score = 0.5066451872734594\n",
      "\n",
      "n_estimators = 10 일때 accuracy = 0.8080603073354595\n",
      "n_estimators = 20 일때 accuracy = 0.799217164395477\n",
      "n_estimators = 30 일때 accuracy = 0.8095100028993911\n",
      "n_estimators = 40 일때 accuracy = 0.8119744853580748\n",
      "n_estimators = 50 일때 accuracy = 0.8116845462452885\n",
      "n_estimators = 60 일때 accuracy = 0.8144389678167585\n",
      "n_estimators = 70 일때 accuracy = 0.8187880545085532\n",
      "n_estimators = 80 일때 accuracy = 0.8196578718469122\n",
      "n_estimators = 90 일때 accuracy = 0.820382719628878\n",
      "n_estimators = 100 일때 accuracy = 0.8224122934183822\n",
      "\n",
      "가장 좋은 f1 score를 가지는 n_estimator는 100 이며,\n",
      "그 값은 f1_score = 0.5066451872734594 입니다.\n",
      "\n",
      "가장 좋은 accucracy를 가지는 n_estimator는 100 입니다.\n",
      "그 값은 accuracy = 0.8224122934183822 입니다.\n"
     ]
    }
   ],
   "source": [
    "list_f1_10to100 = []\n",
    "list_ac_10to100 = []\n",
    "\n",
    "for elem in n_estimators_10to100:\n",
    "    forest = RandomForestClassifier(n_jobs=-1, n_estimators=elem, random_state=42, max_features=round(math.sqrt(len(X_train.columns))))\n",
    "    forest.fit(X_train, y_train)\n",
    "    y_pred = forest.predict(X_val)\n",
    "    list_f1_10to100.append(f1_score(y_val, y_pred))\n",
    "    list_ac_10to100.append(accuracy_score(y_val, y_pred))\n",
    "    \n",
    "list_f1 = list_f1 + list_f1_10to100\n",
    "list_ac = list_ac + list_ac_10to100\n",
    "\n",
    "best_f1_score = -999999\n",
    "best_f1_score_of_index = 0\n",
    "best_accuracy = -999999\n",
    "best_accuracy_of_index = 0\n",
    "\n",
    "print('n_estimators가 10-100 사이에서의 결과\\n')\n",
    "\n",
    "tmp = 0\n",
    "for i in n_estimators_10to100:\n",
    "    print('n_estimators =', i, '일때 f1 score =', list_f1_10to100[tmp])\n",
    "    tmp = tmp + 1\n",
    "\n",
    "print()\n",
    "\n",
    "tmp = 0\n",
    "for i in n_estimators_10to100:\n",
    "    print('n_estimators =', i, '일때 accuracy =', list_ac_10to100[tmp])\n",
    "    tmp = tmp + 1\n",
    "    \n",
    "tmp = -1\n",
    "for i in list_f1_10to100:\n",
    "    tmp = tmp + 1\n",
    "    if best_f1_score < i:\n",
    "        best_f1_score = i\n",
    "        best_f1_score_of_index = tmp\n",
    "\n",
    "print()\n",
    "print('가장 좋은 f1 score를 가지는 n_estimator는', n_estimators_10to100[best_f1_score_of_index], '이며,')\n",
    "print('그 값은 f1_score =', best_f1_score, '입니다.')\n",
    "\n",
    "tmp = -1\n",
    "for i in list_ac_10to100:\n",
    "    tmp = tmp + 1\n",
    "    if best_accuracy < i:\n",
    "        best_accuracy = i\n",
    "        best_accuracy_of_index = tmp\n",
    "      \n",
    "print()\n",
    "print('가장 좋은 accucracy를 가지는 n_estimator는', n_estimators_10to100[best_accuracy_of_index], '입니다.')\n",
    "print('그 값은 accuracy =', best_accuracy, '입니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators가 200-1000 사이에서의 결과\n",
      "\n",
      "n_estimators = 200 일때 f1 score = 0.5006134969325153\n",
      "n_estimators = 300 일때 f1 score = 0.5090616190092631\n",
      "n_estimators = 400 일때 f1 score = 0.5072231139646871\n",
      "n_estimators = 500 일때 f1 score = 0.5046055266319583\n",
      "n_estimators = 600 일때 f1 score = 0.5122244488977955\n",
      "n_estimators = 700 일때 f1 score = 0.5113863363963245\n",
      "n_estimators = 800 일때 f1 score = 0.510228640192539\n",
      "n_estimators = 900 일때 f1 score = 0.5083932853717027\n",
      "n_estimators = 1000 일때 f1 score = 0.5063897763578276\n",
      "\n",
      "n_estimators = 200 일때 accuracy = 0.8229921716439548\n",
      "n_estimators = 300 일때 accuracy = 0.8232821107567411\n",
      "n_estimators = 400 일때 accuracy = 0.8219773847492027\n",
      "n_estimators = 500 일때 accuracy = 0.8206726587416643\n",
      "n_estimators = 600 일때 accuracy = 0.8235720498695274\n",
      "n_estimators = 700 일때 accuracy = 0.8227022325311685\n",
      "n_estimators = 800 일때 accuracy = 0.8229921716439548\n",
      "n_estimators = 900 일때 accuracy = 0.8216874456364164\n",
      "n_estimators = 1000 일때 accuracy = 0.8208176282980574\n",
      "\n",
      "가장 좋은 f1 score를 가지는 n_estimator는 600 이며,\n",
      "그 값은 f1_score = 0.5122244488977955 입니다.\n",
      "\n",
      "가장 좋은 accucracy를 가지는 n_estimator는 600 입니다.\n",
      "그 값은 accuracy = 0.8235720498695274 입니다.\n"
     ]
    }
   ],
   "source": [
    "list_f1_200to1000 = []\n",
    "list_ac_200to1000 = []\n",
    "\n",
    "for elem in n_estimators_200to1000:\n",
    "    forest = RandomForestClassifier(n_jobs=-1, n_estimators=elem, random_state=42, max_features=round(math.sqrt(len(X_train.columns))))\n",
    "    forest.fit(X_train, y_train)\n",
    "    y_pred = forest.predict(X_val)\n",
    "    list_f1_200to1000.append(f1_score(y_val, y_pred))\n",
    "    list_ac_200to1000.append(accuracy_score(y_val, y_pred))\n",
    "\n",
    "list_f1 = list_f1 + list_f1_200to1000\n",
    "list_ac = list_ac + list_ac_200to1000\n",
    "\n",
    "best_f1_score = -999999\n",
    "best_f1_score_of_index = 0\n",
    "best_accuracy = -999999\n",
    "best_accuracy_of_index = 0\n",
    "\n",
    "print('n_estimators가 200-1000 사이에서의 결과\\n')\n",
    "\n",
    "tmp = 0\n",
    "for i in n_estimators_200to1000:\n",
    "    print('n_estimators =', i, '일때 f1 score =', list_f1_200to1000[tmp])\n",
    "    tmp = tmp + 1\n",
    "\n",
    "print()\n",
    "\n",
    "tmp = 0\n",
    "for i in n_estimators_200to1000:\n",
    "    print('n_estimators =', i, '일때 accuracy =', list_ac_200to1000[tmp])\n",
    "    tmp = tmp + 1\n",
    "    \n",
    "tmp = -1\n",
    "for i in list_f1_200to1000:\n",
    "    tmp = tmp + 1\n",
    "    if best_f1_score < i:\n",
    "        best_f1_score = i\n",
    "        best_f1_score_of_index = tmp\n",
    "\n",
    "print()\n",
    "print('가장 좋은 f1 score를 가지는 n_estimator는', n_estimators_200to1000[best_f1_score_of_index], '이며,')\n",
    "print('그 값은 f1_score =', best_f1_score, '입니다.')\n",
    "\n",
    "tmp = -1\n",
    "for i in list_ac_200to1000:\n",
    "    tmp = tmp + 1\n",
    "    if best_accuracy < i:\n",
    "        best_accuracy = i\n",
    "        best_accuracy_of_index = tmp\n",
    "      \n",
    "print()\n",
    "print('가장 좋은 accucracy를 가지는 n_estimator는', n_estimators_200to1000[best_accuracy_of_index], '입니다.')\n",
    "print('그 값은 accuracy =', best_accuracy, '입니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators가 1100-2000 사이에서의 결과\n",
      "\n",
      "n_estimators = 1100 일때 f1 score = 0.5067945643485212\n",
      "n_estimators = 1200 일때 f1 score = 0.510228640192539\n",
      "n_estimators = 1300 일때 f1 score = 0.5104669887278582\n",
      "n_estimators = 1400 일때 f1 score = 0.5131101250504235\n",
      "n_estimators = 1500 일때 f1 score = 0.5129449838187702\n",
      "n_estimators = 1600 일때 f1 score = 0.5119481571486431\n",
      "n_estimators = 1700 일때 f1 score = 0.5111381125961928\n",
      "n_estimators = 1800 일때 f1 score = 0.5133603238866398\n",
      "n_estimators = 1900 일때 f1 score = 0.5139845966761248\n",
      "n_estimators = 2000 일때 f1 score = 0.51338199513382\n",
      "\n",
      "n_estimators = 1100 일때 accuracy = 0.8211075674108437\n",
      "n_estimators = 1200 일때 accuracy = 0.8229921716439548\n",
      "n_estimators = 1300 일때 accuracy = 0.8237170194259206\n",
      "n_estimators = 1400 일때 accuracy = 0.825021745433459\n",
      "n_estimators = 1500 일때 accuracy = 0.8254566541026385\n",
      "n_estimators = 1600 일때 accuracy = 0.8253116845462453\n",
      "n_estimators = 1700 일때 accuracy = 0.825021745433459\n",
      "n_estimators = 1800 일때 accuracy = 0.8257465932154248\n",
      "n_estimators = 1900 일때 accuracy = 0.8261815018846043\n",
      "n_estimators = 2000 일때 accuracy = 0.8260365323282111\n",
      "\n",
      "가장 좋은 f1 score를 가지는 n_estimator는 1900 이며,\n",
      "그 값은 f1_score = 0.5139845966761248 입니다.\n",
      "\n",
      "가장 좋은 accucracy를 가지는 n_estimator는 1900 입니다.\n",
      "그 값은 accuracy = 0.8261815018846043 입니다.\n"
     ]
    }
   ],
   "source": [
    "list_f1_1100to2000 = []\n",
    "list_ac_1100to2000 = []\n",
    "\n",
    "for elem in n_estimators_1100to2000:\n",
    "    forest = RandomForestClassifier(n_jobs=-1, n_estimators=elem, random_state=42, max_features=round(math.sqrt(len(X_train.columns))))\n",
    "    forest.fit(X_train, y_train)\n",
    "    y_pred = forest.predict(X_val)\n",
    "    list_f1_1100to2000.append(f1_score(y_val, y_pred))\n",
    "    list_ac_1100to2000.append(accuracy_score(y_val, y_pred))\n",
    "\n",
    "list_f1 = list_f1 + list_f1_1100to2000\n",
    "list_ac = list_ac + list_ac_1100to2000\n",
    "\n",
    "best_f1_score = -999999\n",
    "best_f1_score_of_index = 0\n",
    "best_accuracy = -999999\n",
    "best_accuracy_of_index = 0\n",
    "\n",
    "print('n_estimators가 1100-2000 사이에서의 결과\\n')\n",
    "\n",
    "tmp = 0\n",
    "for i in n_estimators_1100to2000:\n",
    "    print('n_estimators =', i, '일때 f1 score =', list_f1_1100to2000[tmp])\n",
    "    tmp = tmp + 1\n",
    "\n",
    "print()\n",
    "\n",
    "tmp = 0\n",
    "for i in n_estimators_1100to2000:\n",
    "    print('n_estimators =', i, '일때 accuracy =', list_ac_1100to2000[tmp])\n",
    "    tmp = tmp + 1\n",
    "    \n",
    "tmp = -1\n",
    "for i in list_f1_1100to2000:\n",
    "    tmp = tmp + 1\n",
    "    if best_f1_score < i:\n",
    "        best_f1_score = i\n",
    "        best_f1_score_of_index = tmp\n",
    "\n",
    "print()\n",
    "print('가장 좋은 f1 score를 가지는 n_estimator는', n_estimators_1100to2000[best_f1_score_of_index], '이며,')\n",
    "print('그 값은 f1_score =', best_f1_score, '입니다.')\n",
    "\n",
    "tmp = -1\n",
    "for i in list_ac_1100to2000:\n",
    "    tmp = tmp + 1\n",
    "    if best_accuracy < i:\n",
    "        best_accuracy = i\n",
    "        best_accuracy_of_index = tmp\n",
    "      \n",
    "print()\n",
    "print('가장 좋은 accucracy를 가지는 n_estimator는', n_estimators_1100to2000[best_accuracy_of_index], '입니다.')\n",
    "print('그 값은 accuracy =', best_accuracy, '입니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가장 좋은 모델은 n_estimators = 1900 이며\n",
      "그때의 f1_score = 0.5139845966761248 이다.\n"
     ]
    }
   ],
   "source": [
    "tmp = 0\n",
    "\n",
    "for i in list_f1:\n",
    "    if i > tmp:\n",
    "        tmp = i\n",
    "\n",
    "x = list_f1.index(tmp)\n",
    "\n",
    "if x <= 10:\n",
    "    best_f1 = list_f1_10to100[x]\n",
    "    best_n = n_estimators_10to100[x]\n",
    "elif x <= 19:\n",
    "    x = x - 10\n",
    "    best_f1 = list_f1_200to1000[x]\n",
    "    best_n = n_estimators_200to1000[x]\n",
    "elif x <= 29:\n",
    "    x = x - 19\n",
    "    best_f1 = list_f1_1100to2000[x]\n",
    "    best_n = n_estimators_1100to2000[x]\n",
    "\n",
    "print('가장 좋은 모델은 n_estimators =', best_n, '이며')\n",
    "print('그때의 f1_score =', best_f1, '이다.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_estimators = 90, max_features = round(math.sqrt(len(X_train.columns)))<br>\n",
    "변수 중 fr_yn, dt_of_fr, id 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score : 0.5159209995969367\n",
      "accuracy : 0.825891562771818\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestClassifier(n_jobs=-1, n_estimators=90, random_state=42, max_features=round(math.sqrt(len(X_train.columns))))\n",
    "forest.fit(X_train, y_train)\n",
    "y_pred = forest.predict(X_val)\n",
    "print('f1 score :', f1_score(y_val, y_pred))\n",
    "print('accuracy :', accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = forest.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fr_yn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  fr_yn\n",
       "0     N\n",
       "1     Y\n",
       "2     N\n",
       "3     N\n",
       "4     N"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub['fr_yn'] = predictions\n",
    "sub['fr_yn'] = sub['fr_yn'].map({0:'N', 1:'Y'})\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('yhw8258_화재예측과제_Submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMPAS 결과 0.48816 뜸."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_estimators = 90, max_features = round(math.sqrt(len(X_train.columns)))<br>\n",
    "변수 중 fr_yn, dt_of_fr, id, dt_day 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score : 0.5101214574898785\n",
      "accuracy : 0.8245868367642795\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestClassifier(n_jobs=-1, n_estimators=500, random_state=42, max_features=round(math.sqrt(len(X_train.columns))))\n",
    "forest.fit(X_train, y_train)\n",
    "y_pred = forest.predict(X_val)\n",
    "print('f1 score :', f1_score(y_val, y_pred))\n",
    "print('accuracy :', accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators_10to100 = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "n_estimators_200to1000 = [200, 300, 400, 500, 600, 700, 800, 900, 1000]\n",
    "n_estimators_1100to2000 = [1100, 1200, 1300, 1400, 1500, 1600, 1700, 1800, 1900, 2000]\n",
    "\n",
    "list_f1 = []\n",
    "list_ac = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators가 10-100 사이에서의 결과\n",
      "\n",
      "n_estimators = 10 일때 f1 score = 0.44865082561417635\n",
      "n_estimators = 20 일때 f1 score = 0.4659727782225781\n",
      "n_estimators = 30 일때 f1 score = 0.47232178414974113\n",
      "n_estimators = 40 일때 f1 score = 0.47770700636942676\n",
      "n_estimators = 50 일때 f1 score = 0.4892669096800324\n",
      "n_estimators = 60 일때 f1 score = 0.49193548387096775\n",
      "n_estimators = 70 일때 f1 score = 0.49007695423248276\n",
      "n_estimators = 80 일때 f1 score = 0.4935897435897436\n",
      "n_estimators = 90 일때 f1 score = 0.48529988239905913\n",
      "n_estimators = 100 일때 f1 score = 0.47384382107657314\n",
      "\n",
      "n_estimators = 10 일때 accuracy = 0.8015366772977675\n",
      "n_estimators = 20 일때 accuracy = 0.8066106117715279\n",
      "n_estimators = 30 일때 accuracy = 0.8079153377790664\n",
      "n_estimators = 40 일때 accuracy = 0.8097999420121774\n",
      "n_estimators = 50 일때 accuracy = 0.8171933893882285\n",
      "n_estimators = 60 일때 accuracy = 0.8173383589446216\n",
      "n_estimators = 70 일때 accuracy = 0.8174833285010148\n",
      "n_estimators = 80 일때 accuracy = 0.816758480719049\n",
      "n_estimators = 90 일때 accuracy = 0.8096549724557843\n",
      "n_estimators = 100 일때 accuracy = 0.7987822557262975\n",
      "\n",
      "가장 좋은 f1 score를 가지는 n_estimator는 80 이며,\n",
      "그 값은 f1_score = 0.4935897435897436 입니다.\n",
      "\n",
      "가장 좋은 accucracy를 가지는 n_estimator는 70 입니다.\n",
      "그 값은 accuracy = 0.8174833285010148 입니다.\n"
     ]
    }
   ],
   "source": [
    "list_f1_10to100 = []\n",
    "list_ac_10to100 = []\n",
    "\n",
    "for elem in n_estimators_10to100:\n",
    "    forest = RandomForestClassifier(n_jobs=-1, n_estimators=elem, random_state=42, max_features=round(math.sqrt(len(X_train.columns))))\n",
    "    forest.fit(X_train, y_train)\n",
    "    y_pred = forest.predict(X_val)\n",
    "    list_f1_10to100.append(f1_score(y_val, y_pred))\n",
    "    list_ac_10to100.append(accuracy_score(y_val, y_pred))\n",
    "    \n",
    "list_f1 = list_f1 + list_f1_10to100\n",
    "list_ac = list_ac + list_ac_10to100\n",
    "\n",
    "best_f1_score = -999999\n",
    "best_f1_score_of_index = 0\n",
    "best_accuracy = -999999\n",
    "best_accuracy_of_index = 0\n",
    "\n",
    "print('n_estimators가 10-100 사이에서의 결과\\n')\n",
    "\n",
    "tmp = 0\n",
    "for i in n_estimators_10to100:\n",
    "    print('n_estimators =', i, '일때 f1 score =', list_f1_10to100[tmp])\n",
    "    tmp = tmp + 1\n",
    "\n",
    "print()\n",
    "\n",
    "tmp = 0\n",
    "for i in n_estimators_10to100:\n",
    "    print('n_estimators =', i, '일때 accuracy =', list_ac_10to100[tmp])\n",
    "    tmp = tmp + 1\n",
    "    \n",
    "tmp = -1\n",
    "for i in list_f1_10to100:\n",
    "    tmp = tmp + 1\n",
    "    if best_f1_score < i:\n",
    "        best_f1_score = i\n",
    "        best_f1_score_of_index = tmp\n",
    "\n",
    "print()\n",
    "print('가장 좋은 f1 score를 가지는 n_estimator는', n_estimators_10to100[best_f1_score_of_index], '이며,')\n",
    "print('그 값은 f1_score =', best_f1_score, '입니다.')\n",
    "\n",
    "tmp = -1\n",
    "for i in list_ac_10to100:\n",
    "    tmp = tmp + 1\n",
    "    if best_accuracy < i:\n",
    "        best_accuracy = i\n",
    "        best_accuracy_of_index = tmp\n",
    "      \n",
    "print()\n",
    "print('가장 좋은 accucracy를 가지는 n_estimator는', n_estimators_10to100[best_accuracy_of_index], '입니다.')\n",
    "print('그 값은 accuracy =', best_accuracy, '입니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators가 200-1000 사이에서의 결과\n",
      "\n",
      "n_estimators = 200 일때 f1 score = 0.5049860390905464\n",
      "n_estimators = 300 일때 f1 score = 0.5074148296593186\n",
      "n_estimators = 400 일때 f1 score = 0.5078219013237064\n",
      "n_estimators = 500 일때 f1 score = 0.5101214574898785\n",
      "n_estimators = 600 일때 f1 score = 0.5137096774193548\n",
      "n_estimators = 700 일때 f1 score = 0.5125100887812752\n",
      "n_estimators = 800 일때 f1 score = 0.5141471301535974\n",
      "n_estimators = 900 일때 f1 score = 0.5113821138211382\n",
      "n_estimators = 1000 일때 f1 score = 0.5126324368378158\n",
      "\n",
      "n_estimators = 200 일때 accuracy = 0.8200927805160916\n",
      "n_estimators = 300 일때 accuracy = 0.8218324151928095\n",
      "n_estimators = 400 일때 accuracy = 0.8221223543055958\n",
      "n_estimators = 500 일때 accuracy = 0.8245868367642795\n",
      "n_estimators = 600 일때 accuracy = 0.8251667149898522\n",
      "n_estimators = 700 일때 accuracy = 0.8248767758770659\n",
      "n_estimators = 800 일때 accuracy = 0.8257465932154248\n",
      "n_estimators = 900 일때 accuracy = 0.8257465932154248\n",
      "n_estimators = 1000 일때 accuracy = 0.8266164105537837\n",
      "\n",
      "가장 좋은 f1 score를 가지는 n_estimator는 800 이며,\n",
      "그 값은 f1_score = 0.5141471301535974 입니다.\n",
      "\n",
      "가장 좋은 accucracy를 가지는 n_estimator는 1000 입니다.\n",
      "그 값은 accuracy = 0.8266164105537837 입니다.\n"
     ]
    }
   ],
   "source": [
    "list_f1_200to1000 = []\n",
    "list_ac_200to1000 = []\n",
    "\n",
    "for elem in n_estimators_200to1000:\n",
    "    forest = RandomForestClassifier(n_jobs=-1, n_estimators=elem, random_state=42, max_features=round(math.sqrt(len(X_train.columns))))\n",
    "    forest.fit(X_train, y_train)\n",
    "    y_pred = forest.predict(X_val)\n",
    "    list_f1_200to1000.append(f1_score(y_val, y_pred))\n",
    "    list_ac_200to1000.append(accuracy_score(y_val, y_pred))\n",
    "\n",
    "list_f1 = list_f1 + list_f1_200to1000\n",
    "list_ac = list_ac + list_ac_200to1000\n",
    "\n",
    "best_f1_score = -999999\n",
    "best_f1_score_of_index = 0\n",
    "best_accuracy = -999999\n",
    "best_accuracy_of_index = 0\n",
    "\n",
    "print('n_estimators가 200-1000 사이에서의 결과\\n')\n",
    "\n",
    "tmp = 0\n",
    "for i in n_estimators_200to1000:\n",
    "    print('n_estimators =', i, '일때 f1 score =', list_f1_200to1000[tmp])\n",
    "    tmp = tmp + 1\n",
    "\n",
    "print()\n",
    "\n",
    "tmp = 0\n",
    "for i in n_estimators_200to1000:\n",
    "    print('n_estimators =', i, '일때 accuracy =', list_ac_200to1000[tmp])\n",
    "    tmp = tmp + 1\n",
    "    \n",
    "tmp = -1\n",
    "for i in list_f1_200to1000:\n",
    "    tmp = tmp + 1\n",
    "    if best_f1_score < i:\n",
    "        best_f1_score = i\n",
    "        best_f1_score_of_index = tmp\n",
    "\n",
    "print()\n",
    "print('가장 좋은 f1 score를 가지는 n_estimator는', n_estimators_200to1000[best_f1_score_of_index], '이며,')\n",
    "print('그 값은 f1_score =', best_f1_score, '입니다.')\n",
    "\n",
    "tmp = -1\n",
    "for i in list_ac_200to1000:\n",
    "    tmp = tmp + 1\n",
    "    if best_accuracy < i:\n",
    "        best_accuracy = i\n",
    "        best_accuracy_of_index = tmp\n",
    "      \n",
    "print()\n",
    "print('가장 좋은 accucracy를 가지는 n_estimator는', n_estimators_200to1000[best_accuracy_of_index], '입니다.')\n",
    "print('그 값은 accuracy =', best_accuracy, '입니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_estimators가 1100-2000 사이에서의 결과\n",
      "\n",
      "n_estimators = 1100 일때 f1 score = 0.5148918808649531\n",
      "n_estimators = 1200 일때 f1 score = 0.5148434322895485\n",
      "n_estimators = 1300 일때 f1 score = 0.5127996749288907\n",
      "n_estimators = 1400 일때 f1 score = 0.5103616416091019\n",
      "n_estimators = 1500 일때 f1 score = 0.5136567468406033\n",
      "n_estimators = 1600 일때 f1 score = 0.5115900772671819\n",
      "n_estimators = 1700 일때 f1 score = 0.5131952902963866\n",
      "n_estimators = 1800 일때 f1 score = 0.5116089613034622\n",
      "n_estimators = 1900 일때 f1 score = 0.5130081300813009\n",
      "n_estimators = 2000 일때 f1 score = 0.5124236252545824\n",
      "\n",
      "n_estimators = 1100 일때 accuracy = 0.8276311974485359\n",
      "n_estimators = 1200 일때 accuracy = 0.8270513192229632\n",
      "n_estimators = 1300 일때 accuracy = 0.8261815018846043\n",
      "n_estimators = 1400 일때 accuracy = 0.8253116845462453\n",
      "n_estimators = 1500 일때 accuracy = 0.8270513192229632\n",
      "n_estimators = 1600 일때 accuracy = 0.825891562771818\n",
      "n_estimators = 1700 일때 accuracy = 0.8261815018846043\n",
      "n_estimators = 1800 일때 accuracy = 0.8261815018846043\n",
      "n_estimators = 1900 일때 accuracy = 0.8263264714409974\n",
      "n_estimators = 2000 일때 accuracy = 0.8264714409973906\n",
      "\n",
      "가장 좋은 f1 score를 가지는 n_estimator는 1100 이며,\n",
      "그 값은 f1_score = 0.5148918808649531 입니다.\n",
      "\n",
      "가장 좋은 accucracy를 가지는 n_estimator는 1100 입니다.\n",
      "그 값은 accuracy = 0.8276311974485359 입니다.\n"
     ]
    }
   ],
   "source": [
    "list_f1_1100to2000 = []\n",
    "list_ac_1100to2000 = []\n",
    "\n",
    "for elem in n_estimators_1100to2000:\n",
    "    forest = RandomForestClassifier(n_jobs=-1, n_estimators=elem, random_state=42, max_features=round(math.sqrt(len(X_train.columns))))\n",
    "    forest.fit(X_train, y_train)\n",
    "    y_pred = forest.predict(X_val)\n",
    "    list_f1_1100to2000.append(f1_score(y_val, y_pred))\n",
    "    list_ac_1100to2000.append(accuracy_score(y_val, y_pred))\n",
    "\n",
    "list_f1 = list_f1 + list_f1_1100to2000\n",
    "list_ac = list_ac + list_ac_1100to2000\n",
    "\n",
    "best_f1_score = -999999\n",
    "best_f1_score_of_index = 0\n",
    "best_accuracy = -999999\n",
    "best_accuracy_of_index = 0\n",
    "\n",
    "print('n_estimators가 1100-2000 사이에서의 결과\\n')\n",
    "\n",
    "tmp = 0\n",
    "for i in n_estimators_1100to2000:\n",
    "    print('n_estimators =', i, '일때 f1 score =', list_f1_1100to2000[tmp])\n",
    "    tmp = tmp + 1\n",
    "\n",
    "print()\n",
    "\n",
    "tmp = 0\n",
    "for i in n_estimators_1100to2000:\n",
    "    print('n_estimators =', i, '일때 accuracy =', list_ac_1100to2000[tmp])\n",
    "    tmp = tmp + 1\n",
    "    \n",
    "tmp = -1\n",
    "for i in list_f1_1100to2000:\n",
    "    tmp = tmp + 1\n",
    "    if best_f1_score < i:\n",
    "        best_f1_score = i\n",
    "        best_f1_score_of_index = tmp\n",
    "\n",
    "print()\n",
    "print('가장 좋은 f1 score를 가지는 n_estimator는', n_estimators_1100to2000[best_f1_score_of_index], '이며,')\n",
    "print('그 값은 f1_score =', best_f1_score, '입니다.')\n",
    "\n",
    "tmp = -1\n",
    "for i in list_ac_1100to2000:\n",
    "    tmp = tmp + 1\n",
    "    if best_accuracy < i:\n",
    "        best_accuracy = i\n",
    "        best_accuracy_of_index = tmp\n",
    "      \n",
    "print()\n",
    "print('가장 좋은 accucracy를 가지는 n_estimator는', n_estimators_1100to2000[best_accuracy_of_index], '입니다.')\n",
    "print('그 값은 accuracy =', best_accuracy, '입니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가장 좋은 모델은 n_estimators = 1100 이며\n",
      "그때의 f1_score = 0.5148918808649531 이다.\n"
     ]
    }
   ],
   "source": [
    "tmp = 0\n",
    "\n",
    "for i in list_f1:\n",
    "    if i > tmp:\n",
    "        tmp = i\n",
    "\n",
    "x = list_f1.index(tmp)\n",
    "\n",
    "if x <= 10:\n",
    "    best_f1 = list_f1_10to100[x]\n",
    "    best_n = n_estimators_10to100[x]\n",
    "elif x <= 18:\n",
    "    x = x - 10\n",
    "    best_f1 = list_f1_200to1000[x]\n",
    "    best_n = n_estimators_200to1000[x]\n",
    "elif x <= 28:\n",
    "    x = x - 19\n",
    "    best_f1 = list_f1_1100to2000[x]\n",
    "    best_n = n_estimators_1100to2000[x]\n",
    "\n",
    "print('가장 좋은 모델은 n_estimators =', best_n, '이며')\n",
    "print('그때의 f1_score =', best_f1, '이다.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA 이후 random forest 모델 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X_train_std = StandardScaler().fit_transform(X_train)\n",
    "X_val_std = StandardScaler().fit_transform(X_val)\n",
    "test_std = StandardScaler().fit_transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA n_components= 1\n",
      "f1 score : 0.16776750330250992\n",
      "accuracy : 0.8173383589446216\n",
      "PCA n_components= 2\n",
      "f1 score : 0.12933968686181074\n",
      "accuracy : 0.8145839373731516\n",
      "PCA n_components= 3\n",
      "f1 score : 0.11459192085737842\n",
      "accuracy : 0.6886053928674978\n",
      "PCA n_components= 4\n",
      "f1 score : 0.15807903951975988\n",
      "accuracy : 0.756016236590316\n",
      "PCA n_components= 5\n",
      "f1 score : 0.17293906810035842\n",
      "accuracy : 0.7323861988982314\n",
      "PCA n_components= 6\n",
      "f1 score : 0.1726700971983991\n",
      "accuracy : 0.7902290518991012\n",
      "PCA n_components= 7\n",
      "f1 score : 0.20280474649406688\n",
      "accuracy : 0.7857349956509133\n",
      "PCA n_components= 8\n",
      "f1 score : 0.21997981836528757\n",
      "accuracy : 0.7758770658161787\n",
      "PCA n_components= 9\n",
      "f1 score : 0.16925996204933588\n",
      "accuracy : 0.6826616410553784\n",
      "PCA n_components= 10\n",
      "f1 score : 0.1843506759524785\n",
      "accuracy : 0.7113656132212235\n",
      "PCA n_components= 11\n",
      "f1 score : 0.11438278595696487\n",
      "accuracy : 0.7732676138011018\n",
      "PCA n_components= 12\n",
      "f1 score : 0.19647019647019645\n",
      "accuracy : 0.6501884604233111\n",
      "PCA n_components= 13\n",
      "f1 score : 0.1723721304873137\n",
      "accuracy : 0.7020875616120614\n",
      "PCA n_components= 14\n",
      "f1 score : 0.16009280742459397\n",
      "accuracy : 0.6851261235140621\n",
      "PCA n_components= 15\n",
      "f1 score : 0.17968210089841052\n",
      "accuracy : 0.6558422731226442\n",
      "PCA n_components= 16\n",
      "f1 score : 0.19109026963657677\n",
      "accuracy : 0.5998840243548855\n",
      "PCA n_components= 17\n",
      "f1 score : 0.19061006466123137\n",
      "accuracy : 0.5826326471440998\n",
      "PCA n_components= 18\n",
      "f1 score : 0.15846994535519124\n",
      "accuracy : 0.6874456364163526\n",
      "PCA n_components= 19\n",
      "f1 score : 0.14951245937161428\n",
      "accuracy : 0.6585966946941142\n",
      "PCA n_components= 20\n",
      "f1 score : 0.19465387251542154\n",
      "accuracy : 0.65932154247608\n",
      "PCA n_components= 21\n",
      "f1 score : 0.10905240868184224\n",
      "accuracy : 0.756016236590316\n",
      "PCA n_components= 22\n",
      "f1 score : 0.135706340378198\n",
      "accuracy : 0.7747173093650334\n",
      "PCA n_components= 23\n",
      "f1 score : 0.1706546275395034\n",
      "accuracy : 0.7336909249057698\n",
      "PCA n_components= 24\n",
      "f1 score : 0.1623550401427297\n",
      "accuracy : 0.7277471730936503\n",
      "PCA n_components= 25\n",
      "f1 score : 0.1451225372417107\n",
      "accuracy : 0.7420991591765729\n",
      "PCA n_components= 26\n",
      "f1 score : 0.15949252378794745\n",
      "accuracy : 0.7310814728906929\n",
      "PCA n_components= 27\n",
      "f1 score : 0.15615615615615616\n",
      "accuracy : 0.674108437228182\n",
      "PCA n_components= 28\n",
      "f1 score : 0.14207149404216315\n",
      "accuracy : 0.7286169904320092\n",
      "PCA n_components= 29\n",
      "f1 score : 0.13260173754000917\n",
      "accuracy : 0.7249927515221803\n",
      "PCA n_components= 30\n",
      "f1 score : 0.1326478149100257\n",
      "accuracy : 0.7554363583647434\n"
     ]
    }
   ],
   "source": [
    "from sklearn import decomposition\n",
    "for i in range(1, 31):\n",
    "    pca = decomposition.PCA(n_components=i)\n",
    "    sklearn_pca_X_train = pca.fit_transform(X_train_std)\n",
    "    sklearn_result_X_train = pd.DataFrame(sklearn_pca_X_train, columns=['PC%d' %i for i in range(1, i+1)])\n",
    "    sklearn_pca_X_val = pca.fit_transform(X_val_std)\n",
    "    sklearn_result_X_val = pd.DataFrame(sklearn_pca_X_val, columns=['PC%d' %i for i in range(1, i+1)])\n",
    "    \n",
    "    forest = RandomForestClassifier(n_jobs=-1, n_estimators=100, random_state=42)\n",
    "    forest.fit(sklearn_result_X_train, y_train)\n",
    "    y_pred = forest.predict(sklearn_result_X_val)\n",
    "    print('PCA n_components=',i)\n",
    "    print('f1 score :', f1_score(y_val, y_pred))\n",
    "    print('accuracy :', accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA n_components= 1\n",
      "f1 score : 0.16776750330250992\n",
      "accuracy : 0.8173383589446216\n",
      "PCA n_components= 2\n",
      "f1 score : 0.1306122448979592\n",
      "accuracy : 0.8147289069295448\n",
      "PCA n_components= 3\n",
      "f1 score : 0.1280388978930308\n",
      "accuracy : 0.6880255146419252\n",
      "PCA n_components= 4\n",
      "f1 score : 0.11215718379042161\n",
      "accuracy : 0.6855610321832415\n",
      "PCA n_components= 5\n",
      "f1 score : 0.14110787172011663\n",
      "accuracy : 0.7864598434328791\n",
      "PCA n_components= 6\n",
      "f1 score : 0.17262231995601982\n",
      "accuracy : 0.781820817628298\n",
      "PCA n_components= 7\n",
      "f1 score : 0.2313883299798793\n",
      "accuracy : 0.7784865178312554\n",
      "PCA n_components= 8\n",
      "f1 score : 0.23921568627450981\n",
      "accuracy : 0.7750072484778197\n",
      "PCA n_components= 9\n",
      "f1 score : 0.16980549552330967\n",
      "accuracy : 0.6101768628587997\n",
      "PCA n_components= 10\n",
      "f1 score : 0.16983523447401774\n",
      "accuracy : 0.7151348216874457\n",
      "PCA n_components= 11\n",
      "f1 score : 0.15247524752475247\n",
      "accuracy : 0.7518121194549144\n",
      "PCA n_components= 12\n",
      "f1 score : 0.18040816326530612\n",
      "accuracy : 0.7089011307625399\n",
      "PCA n_components= 13\n",
      "f1 score : 0.13591359135913594\n",
      "accuracy : 0.7216584517251378\n",
      "PCA n_components= 14\n",
      "f1 score : 0.1724449804039795\n",
      "accuracy : 0.6020585677007828\n",
      "PCA n_components= 15\n",
      "f1 score : 0.1581137309292649\n",
      "accuracy : 0.7360104378080603\n",
      "PCA n_components= 16\n",
      "f1 score : 0.12695725772323319\n",
      "accuracy : 0.7009278051609162\n",
      "PCA n_components= 17\n",
      "f1 score : 0.16771333579608422\n",
      "accuracy : 0.6733835894462163\n",
      "PCA n_components= 18\n",
      "f1 score : 0.13000471031559113\n",
      "accuracy : 0.7322412293418382\n",
      "PCA n_components= 19\n",
      "f1 score : 0.1400088613203367\n",
      "accuracy : 0.7186140910408814\n",
      "PCA n_components= 20\n",
      "f1 score : 0.17336977743069112\n",
      "accuracy : 0.6930994491156857\n",
      "PCA n_components= 21\n",
      "f1 score : 0.14594335093614977\n",
      "accuracy : 0.7420991591765729\n",
      "PCA n_components= 22\n",
      "f1 score : 0.12397147558968734\n",
      "accuracy : 0.7684836184401276\n",
      "PCA n_components= 23\n",
      "f1 score : 0.15789473684210525\n",
      "accuracy : 0.7402145549434619\n",
      "PCA n_components= 24\n",
      "f1 score : 0.10596026490066225\n",
      "accuracy : 0.7847202087561612\n",
      "PCA n_components= 25\n",
      "f1 score : 0.12681510164569218\n",
      "accuracy : 0.738474920266744\n",
      "PCA n_components= 26\n",
      "f1 score : 0.1508097165991903\n",
      "accuracy : 0.7567410843722818\n",
      "PCA n_components= 27\n",
      "f1 score : 0.14711359404096833\n",
      "accuracy : 0.7344157726877356\n",
      "PCA n_components= 28\n",
      "f1 score : 0.1787495205216724\n",
      "accuracy : 0.6896201797622499\n",
      "PCA n_components= 29\n",
      "f1 score : 0.13423575860124082\n",
      "accuracy : 0.7774717309365033\n",
      "PCA n_components= 30\n",
      "f1 score : 0.1272627537026879\n",
      "accuracy : 0.7693534357784865\n"
     ]
    }
   ],
   "source": [
    "from sklearn import decomposition\n",
    "for i in range(1, 31):\n",
    "    pca = decomposition.PCA(n_components=i)\n",
    "    sklearn_pca_X_train = pca.fit_transform(X_train_std)\n",
    "    sklearn_result_X_train = pd.DataFrame(sklearn_pca_X_train, columns=['PC%d' %i for i in range(1, i+1)])\n",
    "    sklearn_pca_X_val = pca.fit_transform(X_val_std)\n",
    "    sklearn_result_X_val = pd.DataFrame(sklearn_pca_X_val, columns=['PC%d' %i for i in range(1, i+1)])\n",
    "    \n",
    "    forest = RandomForestClassifier(n_jobs=-1, n_estimators=200, random_state=42)\n",
    "    forest.fit(sklearn_result_X_train, y_train)\n",
    "    y_pred = forest.predict(sklearn_result_X_val)\n",
    "    print('PCA n_components=',i)\n",
    "    print('f1 score :', f1_score(y_val, y_pred))\n",
    "    print('accuracy :', accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
